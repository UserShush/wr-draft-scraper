{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c05d3-ac34-442c-b31d-0c17bf5c5146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42c30b0-ef70-47d6-82b9-fa8dab978592",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     39\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPlayer_ID\u001b[39m\u001b[33m'\u001b[39m: player_id,\n\u001b[32m     40\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCareer_AV\u001b[39m\u001b[33m'\u001b[39m: career_av \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     41\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mGames_Played\u001b[39m\u001b[33m'\u001b[39m: games_played \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     42\u001b[39m     }\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# 🔍 Test it again\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Inspect all comments to see what's in there\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m comment \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcomments\u001b[49m:\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtfoot\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m comment \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mav\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m comment:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m---- COMMENT BLOCK ----\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'comments' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"🔎 Inspecting raw HTML for commented sections...\")\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "for comment in comments:\n",
    "    if 'tfoot' in comment or 'av' in comment:\n",
    "        print(\"---- COMMENT BLOCK ----\")\n",
    "        print(comment[:1000])  # Limit output length\n",
    "        break\n",
    "\n",
    "    # Find all HTML comments\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = None\n",
    "    games_played = None\n",
    "\n",
    "    for comment in comments:\n",
    "        if 'id=\"stats\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            totals_table = comment_soup.find('tfoot')\n",
    "            if totals_table:\n",
    "                row = totals_table.find('tr')\n",
    "                if row:\n",
    "                    games_td = row.find('td', {'data-stat': 'g'})\n",
    "                    av_td = row.find('td', {'data-stat': 'av'})\n",
    "                    if games_td:\n",
    "                        games_played = games_td.text.strip()\n",
    "                    if av_td:\n",
    "                        career_av = av_td.text.strip()\n",
    "                    break\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av or 'N/A',\n",
    "        'Games_Played': games_played or 'N/A'\n",
    "    }\n",
    "\n",
    "# 🔍 Test it again\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9302e838-6aa9-455e-ad16-789f716509fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧩 Found 84 comment blocks on HopkDe00's page\n",
      "\n",
      "🔍 COMMENT BLOCK #1 (First 500 chars)\n",
      "\n",
      " include:start =\"/inc/klecko_header_pfr.html_f\" \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #2 (First 500 chars)\n",
      "\n",
      " no:cookie fast load the css.           \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #3 (First 500 chars)\n",
      "\n",
      " CSS start \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #4 (First 500 chars)\n",
      "\n",
      " CSS END \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #5 (First 500 chars)\n",
      "\n",
      " JS START \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #6 (First 500 chars)\n",
      "\n",
      " JS END \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #7 (First 500 chars)\n",
      "\n",
      " include:end =\"/inc/klecko_header_pfr.html_f\" \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #8 (First 500 chars)\n",
      "\n",
      " HeaderPersonSchema \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #9 (First 500 chars)\n",
      "\n",
      " HeaderPersonSchema:END \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #10 (First 500 chars)\n",
      "\n",
      " HeaderSeoSocial \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #11 (First 500 chars)\n",
      "\n",
      " HeaderSeoSocial:END \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #12 (First 500 chars)\n",
      "\n",
      " tiles, touch, favicons \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #13 (First 500 chars)\n",
      "\n",
      "[if IE]>\n",
      "    <link rel=\"shortcut icon\"                                href=\"https://cdn.ssref.net/req/202504231/favicons/pfr/favicon.ico\"><![endif]\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #14 (First 500 chars)\n",
      "\n",
      " tiles, touch, favicons:end \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #15 (First 500 chars)\n",
      "\n",
      " ad code: begin \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #16 (First 500 chars)\n",
      "\n",
      " ad code:end \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #17 (First 500 chars)\n",
      "\n",
      " ul.user \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #18 (First 500 chars)\n",
      "\n",
      " div#nav \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #19 (First 500 chars)\n",
      "\n",
      " div.search \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #20 (First 500 chars)\n",
      "\n",
      " div#header \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #21 (First 500 chars)\n",
      "\n",
      " no announcement \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #22 (First 500 chars)\n",
      "\n",
      " div.media-item \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #23 (First 500 chars)\n",
      "\n",
      " div#meta \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #24 (First 500 chars)\n",
      "\n",
      "\n",
      "\n",
      "Recognition:\n",
      "\n",
      "* 5x Pro Bowl\n",
      "* 3x All-Pro\n",
      "\n",
      "Uniforms:\n",
      "\n",
      "* Number 10 for Houston Texans 2013-2019\n",
      "* Number 10 for Arizona Cardinals 2020-2022\n",
      "* Number 10 for Tennessee Titans 2023-2024\n",
      "* Number 8 for Kansas City Chiefs 2024\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #25 (First 500 chars)\n",
      "\n",
      " div#fs_fs_300_atf  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #26 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_300_atf \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #27 (First 500 chars)\n",
      "\n",
      " div#info \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #28 (First 500 chars)\n",
      "\n",
      " div#fs_fs_728_atf  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #29 (First 500 chars)\n",
      "\n",
      " sf:blank by design for video ad \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #30 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_728_atf \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #31 (First 500 chars)\n",
      "\n",
      " div#srcom \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #32 (First 500 chars)\n",
      "\n",
      " div#inner_nav \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #33 (First 500 chars)\n",
      "\n",
      " fs_general_header \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #34 (First 500 chars)\n",
      "\n",
      " div#fs_fs_general_header  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #35 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_general_header \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #36 (First 500 chars)\n",
      "\n",
      " fs_btf_1 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #37 (First 500 chars)\n",
      "\n",
      " Tag ID: BTF-1  3-Super unit \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #38 (First 500 chars)\n",
      "\n",
      " Tag ID: pro-football-reference_300x250_BTF-1-1 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #39 (First 500 chars)\n",
      "\n",
      "     <div class=\"section_content\" id=\"div_8814500269\">\n",
      "\t    <ul class=\"news_stories\">\n",
      "<li><strong>4/16</strong> <a rel=\"nofollow noopener\" target=\"_blank\"  href=\"https://www.profootballrumors.com/2025/04/afc-draft-rumors-raiders-membou-jeanty-barron-burden-titans-jackson-texans-grant-bengals-jaguars\" onclick=\"sr_record_analytics_event('newsfeed_click','ProFootballRumors.com', sr_record_directory(),'sr_tracker');\">ProFootballRumors.com: AFC Draft Rumors: Membou, Raiders, Titans, Jackson, Texans, \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #40 (First 500 chars)\n",
      "\n",
      " fs_btf_2 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #41 (First 500 chars)\n",
      "\n",
      " div#fs_fs_btf_2  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #42 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_btf_2 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #43 (First 500 chars)\n",
      "\n",
      "\n",
      "\n",
      "<div class=\"table_container\" id=\"div_fantasy\">\n",
      "    \n",
      "    <table class=\"sortable stats_table\" id=\"fantasy\" data-cols-to-freeze=\",1\">\n",
      "    <caption>Fantasy Table</caption>\n",
      "    \n",
      "\n",
      "   <colgroup><col><col><col><col><col><col><col><col><col></colgroup>\n",
      "   <thead>      \n",
      "      <tr>\n",
      "         <th aria-label=\"Year\" data-stat=\"year_id\" scope=\"col\" class=\" poptip sort_default_asc left\" >Year</th>\n",
      "         <th aria-label=\"Age\" data-stat=\"age\" scope=\"col\" class=\" poptip sort_default_asc center\" data-tip=\"Player\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #44 (First 500 chars)\n",
      "\n",
      " fs_btf_3 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #45 (First 500 chars)\n",
      "\n",
      " div#fs_fs_btf_3  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #46 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_btf_3 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #47 (First 500 chars)\n",
      "\n",
      "\n",
      "\n",
      "<div class=\"table_container\" id=\"div_sim_scores\">\n",
      "    \n",
      "    <table class=\"stats_table\" id=\"sim_scores\" data-cols-to-freeze=\",1\">\n",
      "    <caption>Similar Players Table</caption>\n",
      "    \n",
      "\n",
      "   <colgroup><col><col></colgroup>\n",
      "   <thead>      \n",
      "      <tr>\n",
      "         <th aria-label=\"NumYrs\" data-stat=\"thru_years\" scope=\"col\" class=\" poptip show_partial_when_sorting center\" data-tip=\"<b>Number of years considered at the start of the players career</b>.<br>For example, in the 4 row, you would find players whose \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #48 (First 500 chars)\n",
      "\n",
      " \t<div class=\"data_grid\" id=\"div_leaderboard\" data-entry-type=\"Leaderboards\">\n",
      "<div id=\"leaderboard_awards\" class=\"data_grid_box\">\n",
      "\t<table class=\"no_columns\">\n",
      "\t\t<caption class=\"poptip\" data-tip=\"\">Awards</caption>\t\t<tr class=\"\">\t\t\t<td class=\"single\"><a href=\"/awards/nfl-all-rookie-2013.htm\">2013 NFL All-Rookie Team</a></td>\n",
      "\t\t</tr>\n",
      "\t\t\t\t<tr class=\"\">\t\t\t<td class=\"single\"><a href=\"/awards/2016-nfl-top-100.htm\">2016 NFL Top 100 (#19)</a></td>\n",
      "\t\t</tr>\n",
      "\t\t\t\t<tr class=\"\">\t\t\t<td class=\"single\"><a href=\"/\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #49 (First 500 chars)\n",
      "\n",
      "\n",
      "\n",
      "<div class=\"table_container\" id=\"div_all_pro\">\n",
      "    \n",
      "    <table class=\"sortable stats_table\" id=\"all_pro\" data-cols-to-freeze=\",1\">\n",
      "    <caption>All-Pro Teams Table</caption>\n",
      "    \n",
      "\n",
      "   <colgroup><col><col><col><col><col></colgroup>\n",
      "   <thead>      \n",
      "      <tr>\n",
      "         <th aria-label=\"year\" data-stat=\"year\" scope=\"col\" class=\" poptip center\" >Year</th>\n",
      "         <th aria-label=\"Tm\" data-stat=\"team\" scope=\"col\" class=\" poptip sort_default_asc show_partial_when_sorting left\" >Tm</th>\n",
      "         <th ar\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #50 (First 500 chars)\n",
      "\n",
      "\n",
      "\n",
      "<div class=\"table_container\" id=\"div_combine\">\n",
      "    \n",
      "    <table class=\"sortable stats_table\" id=\"combine\" data-cols-to-freeze=\",1\">\n",
      "    <caption>Combine Measurements Table</caption>\n",
      "    \n",
      "\n",
      "   <colgroup><col><col><col><col><col><col><col><col><col><col></colgroup>\n",
      "   <thead>      \n",
      "      <tr>\n",
      "         <th aria-label=\"Year\" data-stat=\"year_id\" scope=\"col\" class=\" poptip sort_default_asc left\" >Year</th>\n",
      "         <th aria-label=\"Pos\" data-stat=\"pos\" scope=\"col\" class=\" poptip sort_default_asc left\" \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #51 (First 500 chars)\n",
      "\n",
      "     <div class=\"section_content\" id=\"div_transactions\">\n",
      "\t    <p><strong>March 16, 2020</strong>: Traded by <a href=\"/teams/htx/2020.htm\">Texans</a> with 2020 4th round pick (131st overall, <a href=\"https://www.pro-football-reference.com/players/L/LawrRa01.htm\">Rashard Lawrence</a>) to <a href=\"/teams/crd/2020.htm\">Cardinals</a> for 2020 2nd round pick (40th overall, <a href=\"https://www.pro-football-reference.com/players/B/BlacRo00.htm\">Ross Blacklock</a>), 2021 4th round pick (122nd overall su\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #52 (First 500 chars)\n",
      "\n",
      "     <div class=\"section_content\" id=\"div_transactions\">\n",
      "\t    <ul class=\"transactions news_stories\"><li><strong>March 11, 2025:</strong> The <a href=\"/teams/rav/2025.htm\">Baltimore Ravens</a> signed WR <a href=\"/players/H/HopkDe00.htm\">DeAndre Hopkins</a>.</li><li><strong>March 10, 2025:</strong> WR <a href=\"/players/H/HopkDe00.htm\">DeAndre Hopkins</a> elected free agency.</li><li><strong>October 23, 2024:</strong> The <a href=\"/teams/oti/2024.htm\">Tennessee Titans</a> traded WR <a href=\"/player\n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #53 (First 500 chars)\n",
      "\n",
      " global.nonempty_tables_num: 19, table_count: 19 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #54 (First 500 chars)\n",
      "\n",
      " no Local/Partials/NoteBottom.tt2 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #55 (First 500 chars)\n",
      "\n",
      " fs_footer \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #56 (First 500 chars)\n",
      "\n",
      " div#fs_fs_footer  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #57 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_footer \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #58 (First 500 chars)\n",
      "\n",
      " div#content \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #59 (First 500 chars)\n",
      "\n",
      " div#footer_header \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #60 (First 500 chars)\n",
      "\n",
      " div#site_menu \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #61 (First 500 chars)\n",
      "\n",
      " div#social \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #62 (First 500 chars)\n",
      "\n",
      " div#tips_tricks \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #63 (First 500 chars)\n",
      "\n",
      " div#credits \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #64 (First 500 chars)\n",
      "\n",
      " div#about \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #65 (First 500 chars)\n",
      "\n",
      " div#footer \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #66 (First 500 chars)\n",
      "\n",
      " div#wrap \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #67 (First 500 chars)\n",
      "\n",
      " yes sticky url:  https://www.pro-football-reference.com/players/H/HopkDe00.htm \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #68 (First 500 chars)\n",
      "\n",
      " rails \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #69 (First 500 chars)\n",
      "\n",
      " div#fs_fs_rails_left  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #70 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_rails_left \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #71 (First 500 chars)\n",
      "\n",
      " div#fs_fs_rails_right  \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #72 (First 500 chars)\n",
      "\n",
      " /div.#fs_fs_rails_right \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #73 (First 500 chars)\n",
      "\n",
      " sr_gender is used in Templates/Assets/GoogleAnalytics.tt2 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #74 (First 500 chars)\n",
      "\n",
      " Google Analytics \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #75 (First 500 chars)\n",
      "\n",
      " Google Analytics UA,  UA-1890630-3 \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #76 (First 500 chars)\n",
      "\n",
      " Google Analytics GA4, G-EMBDG7RM0K \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #77 (First 500 chars)\n",
      "\n",
      " Google Tag Manager \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #78 (First 500 chars)\n",
      "\n",
      " End Google Tag Manager \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #79 (First 500 chars)\n",
      "\n",
      " Google Tag Manager (noscript) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #80 (First 500 chars)\n",
      "\n",
      " End Google Tag Manager (noscript) \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #81 (First 500 chars)\n",
      "\n",
      " End Google Analytics \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #82 (First 500 chars)\n",
      "\n",
      " Start of HubSpot Embed Code \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #83 (First 500 chars)\n",
      "\n",
      " End of HubSpot Embed Code \n",
      "\n",
      "================================================================================\n",
      "\n",
      "🔍 COMMENT BLOCK #84 (First 500 chars)\n",
      "\n",
      " SR \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def inspect_all_comments(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    print(f\"🧩 Found {len(comments)} comment blocks on {player_id}'s page\")\n",
    "    for i, comment in enumerate(comments):\n",
    "        print(f\"\\n🔍 COMMENT BLOCK #{i+1} (First 500 chars)\\n\")\n",
    "        print(comment[:500])\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run this on DeAndre Hopkins\n",
    "inspect_all_comments(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4b7ffa-6af2-4944-a4b3-0c52c8f3f3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Regular HTML Tables:\n",
      " - receiving_and_rushing\n",
      " - receiving_and_rushing_post\n",
      " - adv_receiving_and_rushing\n",
      " - adv_receiving_and_rushing_post\n",
      " - passing\n",
      " - passing_advanced\n",
      " - defense\n",
      " - defense_post\n",
      " - \n",
      " - scoring\n",
      " - scoring_post\n",
      " - snap_counts\n",
      "\n",
      "🕵️ Tables in Comments:\n",
      " - fantasy (from comment block #43)\n",
      " - sim_scores (from comment block #47)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - None (from comment block #48)\n",
      " - all_pro (from comment block #49)\n",
      " - combine (from comment block #50)\n"
     ]
    }
   ],
   "source": [
    "def list_all_table_ids(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Tables in normal HTML\n",
    "    print(\"🧾 Regular HTML Tables:\")\n",
    "    for table in soup.find_all('table'):\n",
    "        print(f\" - {table.get('id')}\")\n",
    "\n",
    "    # Tables hidden in comments\n",
    "    print(\"\\n🕵️ Tables in Comments:\")\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for i, comment in enumerate(comments):\n",
    "        if '<table' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            for table in comment_soup.find_all('table'):\n",
    "                print(f\" - {table.get('id')} (from comment block #{i+1})\")\n",
    "\n",
    "list_all_table_ids(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f0b701-b8ea-4c8e-9d1f-95a11df371ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No receiving_and_rushing table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"No tfoot in table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "    games_td = row.find('td', {'data-stat': 'g'})\n",
    "    av_td = row.find('td', {'data-stat': 'av'})\n",
    "\n",
    "    games_played = games_td.text.strip() if games_td else 'N/A'\n",
    "    career_av = av_td.text.strip() if av_td else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1548e0b3-a384-42ef-9b80-8a82e848cd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No receiving_and_rushing table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"No tfoot in table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "    games_td = row.find('td', {'data-stat': 'g'})\n",
    "    av_td = row.find('td', {'data-stat': 'av'})\n",
    "\n",
    "    games_played = games_td.text.strip() if games_td else 'N/A'\n",
    "    career_av = av_td.text.strip() if av_td else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab1f1c0-ded9-4889-9c2d-09444a296c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    from bs4 import Comment\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    for comment in comments:\n",
    "        if 'table' in comment and ('receiving_and_rushing' in comment or 'career' in comment):\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            if table:\n",
    "                tfoot = table.find('tfoot')\n",
    "                if tfoot:\n",
    "                    row = tfoot.find('tr')\n",
    "                    if row:\n",
    "                        av_td = row.find('td', {'data-stat': 'av'})\n",
    "                        gp_td = row.find('td', {'data-stat': 'g'})\n",
    "                        if av_td:\n",
    "                            career_av = av_td.text.strip()\n",
    "                        if gp_td:\n",
    "                            games_played = gp_td.text.strip()\n",
    "                        break  # Stop after first valid find\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c52954-0bfe-4591-b496-05e955657eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1402c442-fb44-47a0-9114-0569367ec620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    from bs4 import Comment\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    for comment in comments:\n",
    "        if 'table' in comment and ('receiving_and_rushing' in comment or 'career' in comment):\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table')\n",
    "            if table:\n",
    "                tfoot = table.find('tfoot')\n",
    "                if tfoot:\n",
    "                    row = tfoot.find('tr')\n",
    "                    if row:\n",
    "                        av_td = row.find('td', {'data-stat': 'av'})\n",
    "                        gp_td = row.find('td', {'data-stat': 'g'})\n",
    "                        if av_td:\n",
    "                            career_av = av_td.text.strip()\n",
    "                        if gp_td:\n",
    "                            games_played = gp_td.text.strip()\n",
    "                        break  # Stop after first valid find\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41edfbf5-c3b0-4939-9913-f10fa3a5a8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    from bs4 import Comment\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    for comment in comments:\n",
    "        if 'tfoot' in comment and 'data-stat=\"av\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            row = comment_soup.find('tfoot').find('tr')\n",
    "            if row:\n",
    "                av_td = row.find('td', {'data-stat': 'av'})\n",
    "                gp_td = row.find('td', {'data-stat': 'g'})\n",
    "                if av_td and av_td.text.strip():\n",
    "                    career_av = av_td.text.strip()\n",
    "                if gp_td and gp_td.text.strip():\n",
    "                    games_played = gp_td.text.strip()\n",
    "                break\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27eae11e-d99b-49fc-9e9b-8aa783a02f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = None\n",
    "    for comment in comments:\n",
    "        if 'id=\"all_value\"' in comment or 'tfoot' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            tfoot = comment_soup.find('tfoot')\n",
    "            if tfoot:\n",
    "                row = tfoot.find('tr')\n",
    "                if row:\n",
    "                    av_td = row.find('td', {'data-stat': 'av'})\n",
    "                    if av_td:\n",
    "                        career_av = av_td.text.strip()\n",
    "                        break\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av or 'N/A',\n",
    "        'Games_Played': 'N/A'  # <- still placeholder until we find the right way to extract it\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb74defb-5c89-4407-912f-68f82d5ef962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No receiving_and_rushing table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"No tfoot in table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "    games_td = row.find('td', {'data-stat': 'g'})\n",
    "    av_td = row.find('td', {'data-stat': 'av'})\n",
    "\n",
    "    games_played = games_td.text.strip() if games_td else 'N/A'\n",
    "    career_av = av_td.text.strip() if av_td else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294208fc-9e4c-4621-b6be-119b7b59683b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98302a46-917d-4bc0-b922-ef6c747ee4e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1b985c-d1b3-4ac4-88fd-48d403650211",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 56) (1852942828.py, line 56)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mget_player_stats(\"\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 56)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # === 🕵️ Attempt to extract Career AV from hidden comment block ===\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    career_av = None\n",
    "    for comment in comments:\n",
    "        if 'id=\"value\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            tfoot = comment_soup.find('tfoot')\n",
    "            if tfoot:\n",
    "                row = tfoot.find('tr')\n",
    "                if row:\n",
    "                    av_td = row.find('td', {'data-stat': 'av'})\n",
    "                    if av_td:\n",
    "                        career_av = av_td.text.strip()\n",
    "            break\n",
    "\n",
    "    # === 🧱 Attempt to extract Games Played from visible receiving/rushing table ===\n",
    "    games_played = None\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if table:\n",
    "        tbody = table.find('tbody')\n",
    "        if tbody:\n",
    "            rows = tbody.find_all('tr', class_=lambda x: x != 'thead')\n",
    "            if rows:\n",
    "                last_row = rows[-1]\n",
    "                g_td = last_row.find('td', {'data-stat': 'g'})\n",
    "                if g_td:\n",
    "                    games_played = g_td.text.strip()\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av or 'N/A',\n",
    "        'Games_Played': games_played or 'N/A'\n",
    "    }\n",
    "\n",
    "# 🧪 Try it out\n",
    "get_player_stats(\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a96c896-6bef-49b6-a424-2f5220541db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # === 🕵️ Attempt to extract Career AV from hidden comment block ===\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    career_av = None\n",
    "    for comment in comments:\n",
    "        if 'id=\"value\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            tfoot = comment_soup.find('tfoot')\n",
    "            if tfoot:\n",
    "                row = tfoot.find('tr')\n",
    "                if row:\n",
    "                    av_td = row.find('td', {'data-stat': 'av'})\n",
    "                    if av_td:\n",
    "                        career_av = av_td.text.strip()\n",
    "            break\n",
    "\n",
    "    # === 🧱 Attempt to extract Games Played from visible receiving/rushing table ===\n",
    "    games_played = None\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if table:\n",
    "        tbody = table.find('tbody')\n",
    "        if tbody:\n",
    "            rows = tbody.find_all('tr', class_=lambda x: x != 'thead')\n",
    "            if rows:\n",
    "                last_row = rows[-1]\n",
    "                g_td = last_row.find('td', {'data-stat': 'g'})\n",
    "                if g_td:\n",
    "                    games_played = g_td.text.strip()\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av or 'N/A',\n",
    "        'Games_Played': games_played or 'N/A'\n",
    "    }\n",
    "\n",
    "# 🧪 Try it out\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b141a69-ccee-4285-a9ee-c2b8d07af4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    career_av = None\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    for comment in comments:\n",
    "        if 'table' in comment and 'value' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            table = comment_soup.find('table', {'id': 'value'})\n",
    "            if table:\n",
    "                tfoot = table.find('tfoot')\n",
    "                if tfoot:\n",
    "                    row = tfoot.find('tr')\n",
    "                    av_td = row.find('td', {'data-stat': 'av'}) if row else None\n",
    "                    if av_td:\n",
    "                        career_av = av_td.text.strip()\n",
    "                        break  # We got what we came for\n",
    "\n",
    "    # Try regular table for games played\n",
    "    games_played = None\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if table:\n",
    "        tfoot = table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            games_td = row.find('td', {'data-stat': 'g'}) if row else None\n",
    "            if games_td:\n",
    "                games_played = games_td.text.strip()\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av or 'N/A',\n",
    "        'Games_Played': games_played or 'N/A'\n",
    "    }\n",
    "\n",
    "# Try again\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c93e794d-2397-471d-9454-713a7537eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # ---- Get AV from regular table (your original method)\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    career_av = 'N/A'\n",
    "    if table:\n",
    "        tfoot = table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            if row:\n",
    "                av_td = row.find('td', {'data-stat': 'av'})\n",
    "                if av_td:\n",
    "                    career_av = av_td.text.strip()\n",
    "\n",
    "    # ---- Get Games Played from 'value' table in comment\n",
    "    games_played = 'N/A'\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        if 'value' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            value_table = comment_soup.find('table', {'id': 'value'})\n",
    "            if value_table:\n",
    "                tfoot = value_table.find('tfoot')\n",
    "                if tfoot:\n",
    "                    row = tfoot.find('tr')\n",
    "                    if row:\n",
    "                        g_td = row.find('td', {'data-stat': 'g'})\n",
    "                        if g_td:\n",
    "                            games_played = g_td.text.strip()\n",
    "            break  # Don't keep looping once we’ve found the value table\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# Test call\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689e7799-3ee1-43bc-9ac1-88b4b2e7da2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ No comment block contains 'value'.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import requests\n",
    "\n",
    "def inspect_value_table(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    found = False\n",
    "    for i, comment in enumerate(comments):\n",
    "        if 'value' in comment:\n",
    "            print(f\"\\n🧩 Comment Block #{i} — contains 'value':\\n\")\n",
    "            print(comment[:1500])  # Print first 1500 characters of each for inspection\n",
    "            found = True\n",
    "    if not found:\n",
    "        print(\"❌ No comment block contains 'value'.\")\n",
    "\n",
    "inspect_value_table(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4136dd2-3383-459c-a50e-a7df3601afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': '178'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No receiving_and_rushing table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"No tfoot in table for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "\n",
    "    # Sometimes data-stat=\"g\" is missing, so we try fallback from other columns\n",
    "    games_td = row.find('td', {'data-stat': 'g'}) or row.find('td', string=lambda t: t and t.strip().isdigit())\n",
    "    av_td = row.find('td', {'data-stat': 'av'})\n",
    "\n",
    "    games_played = games_td.text.strip() if games_td else 'N/A'\n",
    "    career_av = av_td.text.strip() if av_td else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b25f1d38-d295-4c6c-be99-c1fba4873139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>College</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Round</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>Tavon Austin</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>DeAndre Hopkins</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>Cordarrelle Patterson</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>Justin Hunter</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>Robert Woods</td>\n",
       "      <td>USC</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                 Player        College  Pick  Round Team\n",
       "0  2013           Tavon Austin  West Virginia     8    NaN  STL\n",
       "1  2013        DeAndre Hopkins        Clemson    27    NaN  HOU\n",
       "2  2013  Cordarrelle Patterson      Tennessee    29    NaN  MIN\n",
       "3  2013          Justin Hunter      Tennessee    34    NaN  TEN\n",
       "4  2013           Robert Woods            USC    41    NaN  BUF"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your cleaned WR draft dataset\n",
    "wr_df = pd.read_csv('wr_draft_data_2013_2022.csv')\n",
    "wr_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a6ec6c-a7e6-4332-b217-813cddb6cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"No receiving_and_rushing table for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"No tfoot in table for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "    games_td = row.find('td', {'data-stat': 'g'})\n",
    "    av_td = row.find('td', {'data-stat': 'av'})\n",
    "\n",
    "    games_played = games_td.text.strip() if games_td else 'N/A'\n",
    "    career_av = av_td.text.strip() if av_td else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbe60c73-9692-4fed-93c2-c17dca96fa26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mPlayer_ID\u001b[39m\u001b[33m'\u001b[39m: player_id, \u001b[33m'\u001b[39m\u001b[33mCareer_AV\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGames_Played\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m}\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Apply to all unique IDs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm  \u001b[38;5;66;03m# optional for progress bar\u001b[39;00m\n\u001b[32m     11\u001b[39m tqdm.pandas()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# If you don't have a Player_ID column, you’ll need to look it up or regenerate\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "# Just to make sure we don’t break everything in case of bad data\n",
    "def safe_stats(player_id):\n",
    "    try:\n",
    "        return get_player_stats(player_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {player_id}: {e}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "# Apply to all unique IDs\n",
    "from tqdm import tqdm  # optional for progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# If you don't have a Player_ID column, you’ll need to look it up or regenerate\n",
    "stats_data = wr_df['Player_ID'].progress_apply(safe_stats)\n",
    "\n",
    "# Convert list of dicts to DataFrame\n",
    "stats_df = pd.DataFrame(stats_data.tolist())\n",
    "\n",
    "# Merge new stats into original\n",
    "wr_enriched_df = wr_df.merge(stats_df, on='Player_ID', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c67098f9-77dd-4e89-8aee-7ef9d37bb64a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Player_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Player_ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     51\u001b[39m wr_df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mwr_draft_data_2013_2022.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m enriched_stats = []\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m player_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mwr_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPlayer_ID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching stats for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     56\u001b[39m     stats = get_player_stats(player_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Player_ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"Failed to fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # ---- Get AV ----\n",
    "    av_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    career_av = 'N/A'\n",
    "    if av_table:\n",
    "        tfoot = av_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            av_td = row.find('td', {'data-stat': 'av'})\n",
    "            if av_td:\n",
    "                career_av = av_td.text.strip()\n",
    "\n",
    "    # ---- Get Games Played ----\n",
    "    info_box = soup.find('div', {'id': 'meta'})\n",
    "    games_played = 'N/A'\n",
    "    if info_box:\n",
    "        for strong in info_box.find_all('strong'):\n",
    "            if strong.text.strip() == 'Games':\n",
    "                parent = strong.parent\n",
    "                if parent and parent.contents:\n",
    "                    games_played = parent.contents[-1].strip()\n",
    "                    break\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# 🧠 Enrich the dataset\n",
    "wr_df = pd.read_csv(\"wr_draft_data_2013_2022.csv\")\n",
    "\n",
    "enriched_stats = []\n",
    "for player_id in wr_df['Player_ID']:\n",
    "    print(f\"Fetching stats for {player_id}...\")\n",
    "    stats = get_player_stats(player_id)\n",
    "    print(stats)\n",
    "    enriched_stats.append(stats)\n",
    "\n",
    "stats_df = pd.DataFrame(enriched_stats)\n",
    "merged_df = wr_df.merge(stats_df, on=\"Player_ID\", how=\"left\")\n",
    "merged_df.to_csv(\"wr_draft_data_enriched.csv\", index=False)\n",
    "print(\"✅ Enriched data saved to 'wr_draft_data_enriched.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f219fa1-e9a3-4424-a46e-f5de0775c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Player', 'College', 'Pick', 'Round', 'Team'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>College</th>\n",
       "      <th>Pick</th>\n",
       "      <th>Round</th>\n",
       "      <th>Team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>Tavon Austin</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>DeAndre Hopkins</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>Cordarrelle Patterson</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>Justin Hunter</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>Robert Woods</td>\n",
       "      <td>USC</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                 Player        College  Pick  Round Team\n",
       "0  2013           Tavon Austin  West Virginia     8    NaN  STL\n",
       "1  2013        DeAndre Hopkins        Clemson    27    NaN  HOU\n",
       "2  2013  Cordarrelle Patterson      Tennessee    29    NaN  MIN\n",
       "3  2013          Justin Hunter      Tennessee    34    NaN  TEN\n",
       "4  2013           Robert Woods            USC    41    NaN  BUF"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wr_draft_data_2013_2022.csv\")\n",
    "print(df.columns)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fe13227-0418-43b3-a315-8e1a57cfa186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "❌ Could not fetch page for HopkDe00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29698023-7d14-440a-9877-512c7e5015db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: AustTa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AustTa00.htm\n",
      "❌ Could not fetch page for AustTa00 (status code: 429)\n",
      "Fetching: HopkDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "❌ Could not fetch page for HopkDe00 (status code: 429)\n",
      "Fetching: PattCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PattCo00.htm\n",
      "❌ Could not fetch page for PattCo00 (status code: 429)\n",
      "Fetching: HuntJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HuntJu00.htm\n",
      "❌ Could not fetch page for HuntJu00 (status code: 429)\n",
      "Fetching: WoodRo02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WoodRo02.htm\n",
      "❌ Could not fetch page for WoodRo02 (status code: 429)\n",
      "Fetching: DobsAa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DobsAa00.htm\n",
      "❌ Could not fetch page for DobsAa00 (status code: 429)\n",
      "Fetching: WillTe01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WillTe01.htm\n",
      "❌ Could not fetch page for WillTe01 (status code: 429)\n",
      "Fetching: AlleKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AlleKe00.htm\n",
      "❌ Could not fetch page for AlleKe00 (status code: 429)\n",
      "Fetching: GoodMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GoodMa00.htm\n",
      "❌ Could not fetch page for GoodMa00 (status code: 429)\n",
      "Fetching: WheaMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WheaMa00.htm\n",
      "❌ Could not fetch page for WheaMa00 (status code: 429)\n",
      "Fetching: BailSt01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BailSt01.htm\n",
      "❌ Could not fetch page for BailSt01 (status code: 429)\n",
      "Fetching: SandAc00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SandAc00.htm\n",
      "❌ Could not fetch page for SandAc00 (status code: 429)\n",
      "Fetching: BoycJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BoycJo00.htm\n",
      "❌ Could not fetch page for BoycJo00 (status code: 429)\n",
      "Fetching: HarpCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HarpCh00.htm\n",
      "❌ Could not fetch page for HarpCh00 (status code: 429)\n",
      "Fetching: PattQu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PattQu00.htm\n",
      "❌ Could not fetch page for PattQu00 (status code: 429)\n",
      "Fetching: RobiDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RobiDe00.htm\n",
      "❌ Could not fetch page for RobiDe00 (status code: 429)\n",
      "Fetching: StilKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StilKe00.htm\n",
      "❌ Could not fetch page for StilKe00 (status code: 429)\n",
      "Fetching: KingTa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/K/KingTa00.htm\n",
      "❌ Could not fetch page for KingTa00 (status code: 429)\n",
      "Fetching: FullCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FullCo00.htm\n",
      "❌ Could not fetch page for FullCo00 (status code: 429)\n",
      "Fetching: SwopRy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SwopRy00.htm\n",
      "❌ Could not fetch page for SwopRy00 (status code: 429)\n",
      "Fetching: BrowJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowJu00.htm\n",
      "❌ Could not fetch page for BrowJu00 (status code: 429)\n",
      "Fetching: BonnAl00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BonnAl00.htm\n",
      "❌ Could not fetch page for BonnAl00 (status code: 429)\n",
      "Fetching: HamiCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HamiCo00.htm\n",
      "❌ Could not fetch page for HamiCo00 (status code: 429)\n",
      "Fetching: ButlBr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/ButlBr00.htm\n",
      "❌ Could not fetch page for ButlBr00 (status code: 429)\n",
      "Fetching: JohnCh08\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnCh08.htm\n",
      "❌ Could not fetch page for JohnCh08 (status code: 429)\n",
      "Fetching: DorsKe01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DorsKe01.htm\n",
      "❌ Could not fetch page for DorsKe01 (status code: 429)\n",
      "Fetching: WilsMa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WilsMa02.htm\n",
      "❌ Could not fetch page for WilsMa02 (status code: 429)\n",
      "Fetching: MellAa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MellAa00.htm\n",
      "❌ Could not fetch page for MellAa00 (status code: 429)\n",
      "Fetching: WatkSa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WatkSa00.htm\n",
      "❌ Could not fetch page for WatkSa00 (status code: 429)\n",
      "Fetching: EvanMi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EvanMi00.htm\n",
      "❌ Could not fetch page for EvanMi00 (status code: 429)\n",
      "Fetching: BeckOd00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BeckOd00.htm\n",
      "❌ Could not fetch page for BeckOd00 (status code: 429)\n",
      "Fetching: CookBr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CookBr00.htm\n",
      "❌ Could not fetch page for CookBr00 (status code: 429)\n",
      "Fetching: BenjKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BenjKe00.htm\n",
      "❌ Could not fetch page for BenjKe00 (status code: 429)\n",
      "Fetching: LeexMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LeexMa00.htm\n",
      "❌ Could not fetch page for LeexMa00 (status code: 429)\n",
      "Fetching: MattJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MattJo00.htm\n",
      "❌ Could not fetch page for MattJo00 (status code: 429)\n",
      "Fetching: RichPa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RichPa01.htm\n",
      "❌ Could not fetch page for RichPa01 (status code: 429)\n",
      "Fetching: AdamDa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AdamDa01.htm\n",
      "❌ Could not fetch page for AdamDa01 (status code: 429)\n",
      "Fetching: LatiCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LatiCo00.htm\n",
      "❌ Could not fetch page for LatiCo00 (status code: 429)\n",
      "Fetching: RobiAl02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RobiAl02.htm\n",
      "❌ Could not fetch page for RobiAl02 (status code: 429)\n",
      "Fetching: LandJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LandJa00.htm\n",
      "❌ Could not fetch page for LandJa00 (status code: 429)\n",
      "Fetching: HuffJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HuffJo00.htm\n",
      "❌ Could not fetch page for HuffJo00 (status code: 429)\n",
      "Fetching: MoncDo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoncDo00.htm\n",
      "❌ Could not fetch page for MoncDo00 (status code: 429)\n",
      "Fetching: BrowJo02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowJo02.htm\n",
      "❌ Could not fetch page for BrowJo02 (status code: 429)\n",
      "Fetching: ArchDr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/ArchDr00.htm\n",
      "❌ Could not fetch page for ArchDr00 (status code: 429)\n",
      "Fetching: SaunJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SaunJa00.htm\n",
      "❌ Could not fetch page for SaunJa00 (status code: 429)\n",
      "Fetching: ElliBr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/ElliBr00.htm\n",
      "❌ Could not fetch page for ElliBr00 (status code: 429)\n",
      "Fetching: EvanSh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EvanSh00.htm\n",
      "❌ Could not fetch page for EvanSh00 (status code: 429)\n",
      "Fetching: BryaMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BryaMa00.htm\n",
      "❌ Could not fetch page for BryaMa00 (status code: 429)\n",
      "Fetching: NorwKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/N/NorwKe00.htm\n",
      "❌ Could not fetch page for NorwKe00 (status code: 429)\n",
      "Fetching: GranRy01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GranRy01.htm\n",
      "❌ Could not fetch page for GranRy01 (status code: 429)\n",
      "Fetching: StreDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StreDe00.htm\n",
      "❌ Could not fetch page for StreDe00 (status code: 429)\n",
      "Fetching: AbbrJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AbbrJa00.htm\n",
      "❌ Could not fetch page for AbbrJa00 (status code: 429)\n",
      "Fetching: HerrRo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HerrRo00.htm\n",
      "❌ Could not fetch page for HerrRo00 (status code: 429)\n",
      "Fetching: JoneT.00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JoneT.00.htm\n",
      "❌ Could not fetch page for JoneT.00 (status code: 429)\n",
      "Fetching: HazeMa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HazeMa01.htm\n",
      "❌ Could not fetch page for HazeMa01 (status code: 429)\n",
      "Fetching: PoweWa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PoweWa00.htm\n",
      "❌ Could not fetch page for PoweWa00 (status code: 429)\n",
      "Fetching: EnunQu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EnunQu00.htm\n",
      "❌ Could not fetch page for EnunQu00 (status code: 429)\n",
      "Fetching: CampMi02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CampMi02.htm\n",
      "❌ Could not fetch page for CampMi02 (status code: 429)\n",
      "Fetching: JaniJe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JaniJe00.htm\n",
      "❌ Could not fetch page for JaniJe00 (status code: 429)\n",
      "Fetching: WrigJa03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WrigJa03.htm\n",
      "❌ Could not fetch page for WrigJa03 (status code: 429)\n",
      "Fetching: ReesTe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/ReesTe00.htm\n",
      "❌ Could not fetch page for ReesTe00 (status code: 429)\n",
      "Fetching: GallJe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GallJe00.htm\n",
      "❌ Could not fetch page for GallJe00 (status code: 429)\n",
      "Fetching: CoopAm00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoopAm00.htm\n",
      "❌ Could not fetch page for CoopAm00 (status code: 429)\n",
      "Fetching: WhitKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WhitKe00.htm\n",
      "❌ Could not fetch page for WhitKe00 (status code: 429)\n",
      "Fetching: ParkDe01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/ParkDe01.htm\n",
      "❌ Could not fetch page for ParkDe01 (status code: 429)\n",
      "Fetching: AghoNe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AghoNe00.htm\n",
      "❌ Could not fetch page for AghoNe00 (status code: 429)\n",
      "Fetching: PerrBr02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PerrBr02.htm\n",
      "❌ Could not fetch page for PerrBr02 (status code: 429)\n",
      "Fetching: DorsPh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DorsPh00.htm\n",
      "❌ Could not fetch page for DorsPh00 (status code: 429)\n",
      "Fetching: SmitDe04\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitDe04.htm\n",
      "❌ Could not fetch page for SmitDe04 (status code: 429)\n",
      "Fetching: GreeDo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GreeDo00.htm\n",
      "❌ Could not fetch page for GreeDo00 (status code: 429)\n",
      "Fetching: LockTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LockTy00.htm\n",
      "❌ Could not fetch page for LockTy00 (status code: 429)\n",
      "Fetching: StroJa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StroJa01.htm\n",
      "❌ Could not fetch page for StroJa01 (status code: 429)\n",
      "Fetching: ConlCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ConlCh00.htm\n",
      "❌ Could not fetch page for ConlCh00 (status code: 429)\n",
      "Fetching: CoatSa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoatSa00.htm\n",
      "❌ Could not fetch page for CoatSa00 (status code: 429)\n",
      "Fetching: MontTy01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MontTy01.htm\n",
      "❌ Could not fetch page for MontTy01 (status code: 429)\n",
      "Fetching: CrowJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CrowJa00.htm\n",
      "❌ Could not fetch page for CrowJa00 (status code: 429)\n",
      "Fetching: HardJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HardJu00.htm\n",
      "❌ Could not fetch page for HardJu00 (status code: 429)\n",
      "Fetching: MaylVi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MaylVi00.htm\n",
      "❌ Could not fetch page for MaylVi00 (status code: 429)\n",
      "Fetching: SmelDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmelDe00.htm\n",
      "❌ Could not fetch page for SmelDe00 (status code: 429)\n",
      "Fetching: GreeRa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GreeRa00.htm\n",
      "❌ Could not fetch page for GreeRa00 (status code: 429)\n",
      "Fetching: DiggSt00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DiggSt00.htm\n",
      "❌ Could not fetch page for DiggSt00 (status code: 429)\n",
      "Fetching: LippTo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LippTo00.htm\n",
      "❌ Could not fetch page for LippTo00 (status code: 429)\n",
      "Fetching: NelsJJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/N/NelsJJ00.htm\n",
      "❌ Could not fetch page for NelsJJ00 (status code: 429)\n",
      "Fetching: BellKe02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BellKe02.htm\n",
      "❌ Could not fetch page for BellKe02 (status code: 429)\n",
      "Fetching: MumpKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MumpKe00.htm\n",
      "❌ Could not fetch page for MumpKe00 (status code: 429)\n",
      "Fetching: ClayKa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ClayKa00.htm\n",
      "❌ Could not fetch page for ClayKa00 (status code: 429)\n",
      "Fetching: DaviGe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DaviGe00.htm\n",
      "❌ Could not fetch page for DaviGe00 (status code: 429)\n",
      "Fetching: SpenEv00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SpenEv00.htm\n",
      "❌ Could not fetch page for SpenEv00 (status code: 429)\n",
      "Fetching: SassBu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SassBu00.htm\n",
      "❌ Could not fetch page for SassBu00 (status code: 429)\n",
      "Fetching: WallDa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WallDa01.htm\n",
      "❌ Could not fetch page for WallDa01 (status code: 429)\n",
      "Fetching: SterNe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SterNe00.htm\n",
      "❌ Could not fetch page for SterNe00 (status code: 429)\n",
      "Fetching: DeboAn00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DeboAn00.htm\n",
      "❌ Could not fetch page for DeboAn00 (status code: 429)\n",
      "Fetching: BrowDa03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowDa03.htm\n",
      "❌ Could not fetch page for BrowDa03 (status code: 429)\n",
      "Fetching: LewiDe02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LewiDe02.htm\n",
      "❌ Could not fetch page for LewiDe02 (status code: 429)\n",
      "Fetching: AlfoMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AlfoMa00.htm\n",
      "❌ Could not fetch page for AlfoMa00 (status code: 429)\n",
      "Fetching: McBrTr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/McBrTr00.htm\n",
      "❌ Could not fetch page for McBrTr00 (status code: 429)\n",
      "Fetching: ColeCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ColeCo00.htm\n",
      "❌ Could not fetch page for ColeCo00 (status code: 429)\n",
      "Fetching: FullWi01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FullWi01.htm\n",
      "❌ Could not fetch page for FullWi01 (status code: 429)\n",
      "Fetching: DoctJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DoctJo00.htm\n",
      "❌ Could not fetch page for DoctJo00 (status code: 429)\n",
      "Fetching: TreaLa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TreaLa00.htm\n",
      "❌ Could not fetch page for TreaLa00 (status code: 429)\n",
      "Fetching: ShepSt00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/ShepSt00.htm\n",
      "❌ Could not fetch page for ShepSt00 (status code: 429)\n",
      "Fetching: ThomMi05\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/ThomMi05.htm\n",
      "❌ Could not fetch page for ThomMi05 (status code: 429)\n",
      "Fetching: BoydTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BoydTy00.htm\n",
      "❌ Could not fetch page for BoydTy00 (status code: 429)\n",
      "Fetching: MillBr03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MillBr03.htm\n",
      "❌ Could not fetch page for MillBr03 (status code: 429)\n",
      "Fetching: CarrLe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CarrLe00.htm\n",
      "❌ Could not fetch page for CarrLe00 (status code: 429)\n",
      "Fetching: MoorCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorCh00.htm\n",
      "❌ Could not fetch page for MoorCh00 (status code: 429)\n",
      "Fetching: MitcMa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MitcMa01.htm\n",
      "❌ Could not fetch page for MitcMa01 (status code: 429)\n",
      "Fetching: LouiRi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LouiRi00.htm\n",
      "❌ Could not fetch page for LouiRi00 (status code: 429)\n",
      "Fetching: CoopPh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoopPh00.htm\n",
      "❌ Could not fetch page for CoopPh00 (status code: 429)\n",
      "Fetching: RobiDe01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RobiDe01.htm\n",
      "❌ Could not fetch page for RobiDe01 (status code: 429)\n",
      "Fetching: SharTa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SharTa00.htm\n",
      "❌ Could not fetch page for SharTa00 (status code: 429)\n",
      "Fetching: PaytJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PaytJo00.htm\n",
      "❌ Could not fetch page for PaytJo00 (status code: 429)\n",
      "Fetching: DaviTr03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DaviTr03.htm\n",
      "❌ Could not fetch page for DaviTr03 (status code: 429)\n",
      "Fetching: HillTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HillTy00.htm\n",
      "❌ Could not fetch page for HillTy00 (status code: 429)\n",
      "Fetching: HiggRa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HiggRa00.htm\n",
      "❌ Could not fetch page for HiggRa00 (status code: 429)\n",
      "Fetching: BoehMo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BoehMo00.htm\n",
      "❌ Could not fetch page for BoehMo00 (status code: 429)\n",
      "Fetching: GranJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GranJa00.htm\n",
      "❌ Could not fetch page for GranJa00 (status code: 429)\n",
      "Fetching: ListKo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/ListKo00.htm\n",
      "❌ Could not fetch page for ListKo00 (status code: 429)\n",
      "Fetching: CoreCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoreCo00.htm\n",
      "❌ Could not fetch page for CoreCo00 (status code: 429)\n",
      "Fetching: ThomMi04\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/ThomMi04.htm\n",
      "❌ Could not fetch page for ThomMi04 (status code: 429)\n",
      "Fetching: BurbAa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BurbAa00.htm\n",
      "❌ Could not fetch page for BurbAa00 (status code: 429)\n",
      "Fetching: LuciDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LuciDe00.htm\n",
      "❌ Could not fetch page for LuciDe00 (status code: 429)\n",
      "Fetching: AyerDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AyerDe00.htm\n",
      "❌ Could not fetch page for AyerDe00 (status code: 429)\n",
      "Fetching: BravDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BravDa00.htm\n",
      "❌ Could not fetch page for BravDa00 (status code: 429)\n",
      "Fetching: FullDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FullDe00.htm\n",
      "❌ Could not fetch page for FullDe00 (status code: 429)\n",
      "Fetching: PeakCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PeakCh00.htm\n",
      "❌ Could not fetch page for PeakCh00 (status code: 429)\n",
      "Fetching: LawlKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LawlKe00.htm\n",
      "❌ Could not fetch page for LawlKe00 (status code: 429)\n",
      "Fetching: DaviCo03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DaviCo03.htm\n",
      "❌ Could not fetch page for DaviCo03 (status code: 429)\n",
      "Fetching: WillMi07\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WillMi07.htm\n",
      "❌ Could not fetch page for WillMi07 (status code: 429)\n",
      "Fetching: RossJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RossJo00.htm\n",
      "❌ Could not fetch page for RossJo00 (status code: 429)\n",
      "Fetching: JoneZa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JoneZa00.htm\n",
      "❌ Could not fetch page for JoneZa00 (status code: 429)\n",
      "Fetching: SamuCu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SamuCu00.htm\n",
      "❌ Could not fetch page for SamuCu00 (status code: 429)\n",
      "Fetching: SmitJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitJu00.htm\n",
      "❌ Could not fetch page for SmitJu00 (status code: 429)\n",
      "Fetching: KuppCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/K/KuppCo00.htm\n",
      "❌ Could not fetch page for KuppCo00 (status code: 429)\n",
      "Fetching: TaylTa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TaylTa00.htm\n",
      "❌ Could not fetch page for TaylTa00 (status code: 429)\n",
      "Fetching: StewAr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StewAr00.htm\n",
      "❌ Could not fetch page for StewAr00 (status code: 429)\n",
      "Fetching: HendCa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HendCa01.htm\n",
      "❌ Could not fetch page for HendCa01 (status code: 429)\n",
      "Fetching: GodwCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GodwCh00.htm\n",
      "❌ Could not fetch page for GodwCh00 (status code: 429)\n",
      "Fetching: GollKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GollKe00.htm\n",
      "❌ Could not fetch page for GollKe00 (status code: 429)\n",
      "Fetching: WillCh05\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WillCh05.htm\n",
      "❌ Could not fetch page for WillCh05 (status code: 429)\n",
      "Fetching: DarbAm00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DarbAm00.htm\n",
      "❌ Could not fetch page for DarbAm00 (status code: 429)\n",
      "Fetching: WestDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WestDe00.htm\n",
      "❌ Could not fetch page for WestDe00 (status code: 429)\n",
      "Fetching: ReynJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/ReynJo00.htm\n",
      "❌ Could not fetch page for ReynJo00 (status code: 429)\n",
      "Fetching: HollMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HollMa00.htm\n",
      "❌ Could not fetch page for HollMa00 (status code: 429)\n",
      "Fetching: MaloJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MaloJo00.htm\n",
      "❌ Could not fetch page for MaloJo00 (status code: 429)\n",
      "Fetching: SwitRy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SwitRy00.htm\n",
      "❌ Could not fetch page for SwitRy00 (status code: 429)\n",
      "Fetching: ChesJe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ChesJe00.htm\n",
      "❌ Could not fetch page for ChesJe00 (status code: 429)\n",
      "Fetching: HansCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HansCh00.htm\n",
      "❌ Could not fetch page for HansCh00 (status code: 429)\n",
      "Fetching: GibsSh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GibsSh00.htm\n",
      "❌ Could not fetch page for GibsSh00 (status code: 429)\n",
      "Fetching: AdamRo01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AdamRo01.htm\n",
      "❌ Could not fetch page for AdamRo01 (status code: 429)\n",
      "Fetching: McKeIs00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/McKeIs00.htm\n",
      "❌ Could not fetch page for McKeIs00 (status code: 429)\n",
      "Fetching: YancDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/Y/YancDe00.htm\n",
      "❌ Could not fetch page for YancDe00 (status code: 429)\n",
      "Fetching: TaylTr02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TaylTr02.htm\n",
      "❌ Could not fetch page for TaylTr02 (status code: 429)\n",
      "Fetching: DaviRo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DaviRo00.htm\n",
      "❌ Could not fetch page for DaviRo00 (status code: 429)\n",
      "Fetching: ColeSt00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ColeSt00.htm\n",
      "❌ Could not fetch page for ColeSt00 (status code: 429)\n",
      "Fetching: MoorDa03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorDa03.htm\n",
      "❌ Could not fetch page for MoorDa03 (status code: 429)\n",
      "Fetching: FordIs00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FordIs00.htm\n",
      "❌ Could not fetch page for FordIs00 (status code: 429)\n",
      "Fetching: BrowNo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowNo00.htm\n",
      "❌ Could not fetch page for BrowNo00 (status code: 429)\n",
      "Fetching: DuprMa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DuprMa01.htm\n",
      "❌ Could not fetch page for DuprMa01 (status code: 429)\n",
      "Fetching: MoorD.00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorD.00.htm\n",
      "❌ Could not fetch page for MoorD.00 (status code: 429)\n",
      "Fetching: RidlCa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RidlCa00.htm\n",
      "❌ Could not fetch page for RidlCa00 (status code: 429)\n",
      "Fetching: SuttCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SuttCo00.htm\n",
      "❌ Could not fetch page for SuttCo00 (status code: 429)\n",
      "Fetching: PettDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PettDa00.htm\n",
      "❌ Could not fetch page for PettDa00 (status code: 429)\n",
      "Fetching: KirkCh01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/K/KirkCh01.htm\n",
      "❌ Could not fetch page for KirkCh01 (status code: 429)\n",
      "Fetching: MillAn02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MillAn02.htm\n",
      "❌ Could not fetch page for MillAn02 (status code: 429)\n",
      "Fetching: WashJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WashJa00.htm\n",
      "❌ Could not fetch page for WashJa00 (status code: 429)\n",
      "Fetching: CharDJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CharDJ00.htm\n",
      "❌ Could not fetch page for CharDJ00 (status code: 429)\n",
      "Fetching: GallMi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GallMi00.htm\n",
      "❌ Could not fetch page for GallMi00 (status code: 429)\n",
      "Fetching: SmitTr03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitTr03.htm\n",
      "❌ Could not fetch page for SmitTr03 (status code: 429)\n",
      "Fetching: CoutKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoutKe00.htm\n",
      "❌ Could not fetch page for CoutKe00 (status code: 429)\n",
      "Fetching: CallAn00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CallAn00.htm\n",
      "❌ Could not fetch page for CallAn00 (status code: 429)\n",
      "Fetching: HamiDa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HamiDa01.htm\n",
      "❌ Could not fetch page for HamiDa01 (status code: 429)\n",
      "Fetching: ScotJa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/ScotJa02.htm\n",
      "❌ Could not fetch page for ScotJa02 (status code: 429)\n",
      "Fetching: MoorJM00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorJM00.htm\n",
      "❌ Could not fetch page for MoorJM00 (status code: 429)\n",
      "Fetching: WatsJu01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WatsJu01.htm\n",
      "❌ Could not fetch page for WatsJu01 (status code: 429)\n",
      "Fetching: FounDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FounDa00.htm\n",
      "❌ Could not fetch page for FounDa00 (status code: 429)\n",
      "Fetching: LaslJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LaslJo00.htm\n",
      "❌ Could not fetch page for LaslJo00 (status code: 429)\n",
      "Fetching: ValdMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/V/ValdMa00.htm\n",
      "❌ Could not fetch page for ValdMa00 (status code: 429)\n",
      "Fetching: RatlDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RatlDa00.htm\n",
      "❌ Could not fetch page for RatlDa00 (status code: 429)\n",
      "Fetching: CainDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CainDe00.htm\n",
      "❌ Could not fetch page for CainDe00 (status code: 429)\n",
      "Fetching: McClRa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/McClRa00.htm\n",
      "❌ Could not fetch page for McClRa00 (status code: 429)\n",
      "Fetching: CantDy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CantDy00.htm\n",
      "❌ Could not fetch page for CantDy00 (status code: 429)\n",
      "Fetching: GageRu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GageRu00.htm\n",
      "❌ Could not fetch page for GageRu00 (status code: 429)\n",
      "Fetching: SmitTr04\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitTr04.htm\n",
      "❌ Could not fetch page for SmitTr04 (status code: 429)\n",
      "Fetching: St.BEq00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/St.BEq00.htm\n",
      "❌ Could not fetch page for St.BEq00 (status code: 429)\n",
      "Fetching: WilsCe01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WilsCe01.htm\n",
      "❌ Could not fetch page for WilsCe01 (status code: 429)\n",
      "Fetching: BerrBr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BerrBr00.htm\n",
      "❌ Could not fetch page for BerrBr00 (status code: 429)\n",
      "Fetching: WimsJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WimsJa00.htm\n",
      "❌ Could not fetch page for WimsJa00 (status code: 429)\n",
      "Fetching: AtemMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AtemMa00.htm\n",
      "❌ Could not fetch page for AtemMa00 (status code: 429)\n",
      "Fetching: JameRi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JameRi00.htm\n",
      "❌ Could not fetch page for JameRi00 (status code: 429)\n",
      "Fetching: TateAu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TateAu00.htm\n",
      "❌ Could not fetch page for TateAu00 (status code: 429)\n",
      "Fetching: ProeAu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/ProeAu00.htm\n",
      "❌ Could not fetch page for ProeAu00 (status code: 429)\n",
      "Fetching: QuinTr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/Q/QuinTr00.htm\n",
      "❌ Could not fetch page for QuinTr00 (status code: 429)\n",
      "Fetching: BrowMa04\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowMa04.htm\n",
      "❌ Could not fetch page for BrowMa04 (status code: 429)\n",
      "Fetching: HarrNK00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HarrNK00.htm\n",
      "❌ Could not fetch page for HarrNK00 (status code: 429)\n",
      "Fetching: SamuDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SamuDe00.htm\n",
      "❌ Could not fetch page for SamuDe00 (status code: 429)\n",
      "Fetching: BrowAJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowAJ00.htm\n",
      "❌ Could not fetch page for BrowAJ00 (status code: 429)\n",
      "Fetching: HardMe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HardMe00.htm\n",
      "❌ Could not fetch page for HardMe00 (status code: 429)\n",
      "Fetching: ArceJJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/ArceJJ00.htm\n",
      "❌ Could not fetch page for ArceJJ00 (status code: 429)\n",
      "Fetching: CampPa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CampPa00.htm\n",
      "❌ Could not fetch page for CampPa00 (status code: 429)\n",
      "Fetching: IsabAn00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/I/IsabAn00.htm\n",
      "❌ Could not fetch page for IsabAn00 (status code: 429)\n",
      "Fetching: MetcDK00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MetcDK00.htm\n",
      "❌ Could not fetch page for MetcDK00 (status code: 429)\n",
      "Fetching: JohnDi01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnDi01.htm\n",
      "❌ Could not fetch page for JohnDi01 (status code: 429)\n",
      "Fetching: HurdJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HurdJa00.htm\n",
      "❌ Could not fetch page for HurdJa00 (status code: 429)\n",
      "Fetching: McLaTe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/McLaTe00.htm\n",
      "❌ Could not fetch page for McLaTe00 (status code: 429)\n",
      "Fetching: BoykMi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BoykMi00.htm\n",
      "❌ Could not fetch page for BoykMi00 (status code: 429)\n",
      "Fetching: ButlHa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/ButlHa00.htm\n",
      "❌ Could not fetch page for ButlHa00 (status code: 429)\n",
      "Fetching: JennGa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JennGa00.htm\n",
      "❌ Could not fetch page for JennGa00 (status code: 429)\n",
      "Fetching: RidlRi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RidlRi00.htm\n",
      "❌ Could not fetch page for RidlRi00 (status code: 429)\n",
      "Fetching: RenfHu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RenfHu00.htm\n",
      "❌ Could not fetch page for RenfHu00 (status code: 429)\n",
      "Fetching: SlayDa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SlayDa01.htm\n",
      "❌ Could not fetch page for SlayDa01 (status code: 429)\n",
      "Fetching: JohnKe07\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnKe07.htm\n",
      "❌ Could not fetch page for JohnKe07 (status code: 429)\n",
      "Fetching: FulgTr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FulgTr00.htm\n",
      "❌ Could not fetch page for FulgTr00 (status code: 429)\n",
      "Fetching: WinfJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WinfJu00.htm\n",
      "❌ Could not fetch page for WinfJu00 (status code: 429)\n",
      "Fetching: GreeMa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GreeMa02.htm\n",
      "❌ Could not fetch page for GreeMa02 (status code: 429)\n",
      "Fetching: HarmKe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HarmKe00.htm\n",
      "❌ Could not fetch page for HarmKe00 (status code: 429)\n",
      "Fetching: MillSc01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MillSc01.htm\n",
      "❌ Could not fetch page for MillSc01 (status code: 429)\n",
      "Fetching: UrsuJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/U/UrsuJo00.htm\n",
      "❌ Could not fetch page for UrsuJo00 (status code: 429)\n",
      "Fetching: GodwTe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GodwTe00.htm\n",
      "❌ Could not fetch page for GodwTe00 (status code: 429)\n",
      "Fetching: MitcDi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MitcDi00.htm\n",
      "❌ Could not fetch page for MitcDi00 (status code: 429)\n",
      "Fetching: JohnOl00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnOl00.htm\n",
      "❌ Could not fetch page for JohnOl00 (status code: 429)\n",
      "Fetching: RuggHe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RuggHe00.htm\n",
      "❌ Could not fetch page for RuggHe00 (status code: 429)\n",
      "Fetching: JeudJe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JeudJe00.htm\n",
      "❌ Could not fetch page for JeudJe00 (status code: 429)\n",
      "Fetching: LambCe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LambCe00.htm\n",
      "❌ Could not fetch page for LambCe00 (status code: 429)\n",
      "Fetching: ReagJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/ReagJa00.htm\n",
      "❌ Could not fetch page for ReagJa00 (status code: 429)\n",
      "Fetching: JeffJu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JeffJu00.htm\n",
      "❌ Could not fetch page for JeffJu00 (status code: 429)\n",
      "Fetching: AiyuBr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AiyuBr00.htm\n",
      "❌ Could not fetch page for AiyuBr00 (status code: 429)\n",
      "Fetching: HiggTe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HiggTe00.htm\n",
      "❌ Could not fetch page for HiggTe00 (status code: 429)\n",
      "Fetching: PittMi01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PittMi01.htm\n",
      "❌ Could not fetch page for PittMi01 (status code: 429)\n",
      "Fetching: ShenLa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/ShenLa00.htm\n",
      "❌ Could not fetch page for ShenLa00 (status code: 429)\n",
      "Fetching: HamlKJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HamlKJ00.htm\n",
      "❌ Could not fetch page for HamlKJ00 (status code: 429)\n",
      "Fetching: ClayCh01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ClayCh01.htm\n",
      "❌ Could not fetch page for ClayCh01 (status code: 429)\n",
      "Fetching: JeffVa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JeffVa00.htm\n",
      "❌ Could not fetch page for JeffVa00 (status code: 429)\n",
      "Fetching: MimsDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MimsDe00.htm\n",
      "❌ Could not fetch page for MimsDe00 (status code: 429)\n",
      "Fetching: BowdLy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BowdLy00.htm\n",
      "❌ Could not fetch page for BowdLy00 (status code: 429)\n",
      "Fetching: EdwaBr01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EdwaBr01.htm\n",
      "❌ Could not fetch page for EdwaBr01 (status code: 429)\n",
      "Fetching: DuveDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DuveDe00.htm\n",
      "❌ Could not fetch page for DuveDe00 (status code: 429)\n",
      "Fetching: DaviGa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DaviGa01.htm\n",
      "❌ Could not fetch page for DaviGa01 (status code: 429)\n",
      "Fetching: GandAn00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GandAn00.htm\n",
      "❌ Could not fetch page for GandAn00 (status code: 429)\n",
      "Fetching: ReedJo03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/ReedJo03.htm\n",
      "❌ Could not fetch page for ReedJo03 (status code: 429)\n",
      "Fetching: JohnTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnTy00.htm\n",
      "❌ Could not fetch page for JohnTy00 (status code: 429)\n",
      "Fetching: JohnCo01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JohnCo01.htm\n",
      "❌ Could not fetch page for JohnCo01 (status code: 429)\n",
      "Fetching: CephQu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CephQu00.htm\n",
      "❌ Could not fetch page for CephQu00 (status code: 429)\n",
      "Fetching: HighJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HighJo00.htm\n",
      "❌ Could not fetch page for HighJo00 (status code: 429)\n",
      "Fetching: CoulIs00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CoulIs00.htm\n",
      "❌ Could not fetch page for CoulIs00 (status code: 429)\n",
      "Fetching: MoonDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoonDa00.htm\n",
      "❌ Could not fetch page for MoonDa00 (status code: 429)\n",
      "Fetching: OsboKJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/O/OsboKJ00.htm\n",
      "❌ Could not fetch page for OsboKJ00 (status code: 429)\n",
      "Fetching: PeopDo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PeopDo00.htm\n",
      "❌ Could not fetch page for PeopDo00 (status code: 429)\n",
      "Fetching: WatkQu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WatkQu00.htm\n",
      "❌ Could not fetch page for WatkQu00 (status code: 429)\n",
      "Fetching: ProcJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/ProcJa00.htm\n",
      "❌ Could not fetch page for ProcJa00 (status code: 429)\n",
      "Fetching: HodgIs00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HodgIs00.htm\n",
      "❌ Could not fetch page for HodgIs00 (status code: 429)\n",
      "Fetching: PatmDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PatmDe00.htm\n",
      "❌ Could not fetch page for PatmDe00 (status code: 429)\n",
      "Fetching: SwaiFr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SwaiFr00.htm\n",
      "❌ Could not fetch page for SwaiFr00 (status code: 429)\n",
      "Fetching: JennJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JennJa00.htm\n",
      "❌ Could not fetch page for JennJa00 (status code: 429)\n",
      "Fetching: HillKJ00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HillKJ00.htm\n",
      "❌ Could not fetch page for HillKJ00 (status code: 429)\n",
      "Fetching: ClevTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ClevTy00.htm\n",
      "❌ Could not fetch page for ClevTy00 (status code: 429)\n",
      "Fetching: ChasJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/ChasJa00.htm\n",
      "❌ Could not fetch page for ChasJa00 (status code: 429)\n",
      "Fetching: WaddJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WaddJa00.htm\n",
      "❌ Could not fetch page for WaddJa00 (status code: 429)\n",
      "Fetching: SmitDe07\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitDe07.htm\n",
      "❌ Could not fetch page for SmitDe07 (status code: 429)\n",
      "Fetching: ToneKa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/ToneKa00.htm\n",
      "❌ Could not fetch page for ToneKa00 (status code: 429)\n",
      "Fetching: BateRa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BateRa00.htm\n",
      "❌ Could not fetch page for BateRa00 (status code: 429)\n",
      "Fetching: MoorEl00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorEl00.htm\n",
      "❌ Could not fetch page for MoorEl00 (status code: 429)\n",
      "Fetching: MoorRo02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorRo02.htm\n",
      "❌ Could not fetch page for MoorRo02 (status code: 429)\n",
      "Fetching: EskrDW00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EskrDW00.htm\n",
      "❌ Could not fetch page for EskrDW00 (status code: 429)\n",
      "Fetching: AtweTu00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AtweTu00.htm\n",
      "❌ Could not fetch page for AtweTu00 (status code: 429)\n",
      "Fetching: MarsTe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MarsTe00.htm\n",
      "❌ Could not fetch page for MarsTe00 (status code: 429)\n",
      "Fetching: PalmJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PalmJo00.htm\n",
      "❌ Could not fetch page for PalmJo00 (status code: 429)\n",
      "Fetching: BrowDy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BrowDy00.htm\n",
      "❌ Could not fetch page for BrowDy00 (status code: 429)\n",
      "Fetching: RodgAm00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RodgAm00.htm\n",
      "❌ Could not fetch page for RodgAm00 (status code: 429)\n",
      "Fetching: CollNi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CollNi00.htm\n",
      "❌ Could not fetch page for CollNi00 (status code: 429)\n",
      "Fetching: SchwAn00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SchwAn00.htm\n",
      "❌ Could not fetch page for SchwAn00 (status code: 429)\n",
      "Fetching: FitzDe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FitzDe00.htm\n",
      "❌ Could not fetch page for FitzDe00 (status code: 429)\n",
      "Fetching: StxxAm00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StxxAm00.htm\n",
      "❌ Could not fetch page for StxxAm00 (status code: 429)\n",
      "Fetching: DardJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DardJa00.htm\n",
      "❌ Could not fetch page for DardJa00 (status code: 429)\n",
      "Fetching: WallTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WallTy00.htm\n",
      "❌ Could not fetch page for WallTy00 (status code: 429)\n",
      "Fetching: HarrJa03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HarrJa03.htm\n",
      "❌ Could not fetch page for HarrJa03 (status code: 429)\n",
      "Fetching: SmitIh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitIh00.htm\n",
      "❌ Could not fetch page for SmitIh00 (status code: 429)\n",
      "Fetching: FehoSi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/F/FehoSi00.htm\n",
      "❌ Could not fetch page for FehoSi00 (status code: 429)\n",
      "Fetching: PoweCo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PoweCo00.htm\n",
      "❌ Could not fetch page for PoweCo00 (status code: 429)\n",
      "Fetching: DarbFr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DarbFr00.htm\n",
      "❌ Could not fetch page for DarbFr00 (status code: 429)\n",
      "Fetching: StevMa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StevMa00.htm\n",
      "❌ Could not fetch page for StevMa00 (status code: 429)\n",
      "Fetching: SmitSh03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SmitSh03.htm\n",
      "❌ Could not fetch page for SmitSh03 (status code: 429)\n",
      "Fetching: McMaRa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/McMaRa00.htm\n",
      "❌ Could not fetch page for McMaRa00 (status code: 429)\n",
      "Fetching: CampJa03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/C/CampJa03.htm\n",
      "❌ Could not fetch page for CampJa03 (status code: 429)\n",
      "Fetching: WillSe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WillSe00.htm\n",
      "❌ Could not fetch page for WillSe00 (status code: 429)\n",
      "Fetching: NewsDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/N/NewsDa00.htm\n",
      "❌ Could not fetch page for NewsDa00 (status code: 429)\n",
      "Fetching: StraMi03\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/StraMi03.htm\n",
      "❌ Could not fetch page for StraMi03 (status code: 429)\n",
      "Fetching: NixoTr01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/N/NixoTr01.htm\n",
      "❌ Could not fetch page for NixoTr01 (status code: 429)\n",
      "Fetching: SkowBe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/SkowBe00.htm\n",
      "❌ Could not fetch page for SkowBe00 (status code: 429)\n",
      "Fetching: BakeKa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BakeKa00.htm\n",
      "❌ Could not fetch page for BakeKa00 (status code: 429)\n",
      "Fetching: MilnDa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MilnDa00.htm\n",
      "❌ Could not fetch page for MilnDa00 (status code: 429)\n",
      "Fetching: LondDr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/L/LondDr00.htm\n",
      "❌ Could not fetch page for LondDr00 (status code: 429)\n",
      "Fetching: WilsGa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WilsGa00.htm\n",
      "❌ Could not fetch page for WilsGa00 (status code: 429)\n",
      "Fetching: OlavCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/O/OlavCh00.htm\n",
      "❌ Could not fetch page for OlavCh00 (status code: 429)\n",
      "Fetching: WillJa11\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WillJa11.htm\n",
      "❌ Could not fetch page for WillJa11 (status code: 429)\n",
      "Fetching: DotsJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DotsJa00.htm\n",
      "❌ Could not fetch page for DotsJa00 (status code: 429)\n",
      "Fetching: BurkTr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BurkTr00.htm\n",
      "❌ Could not fetch page for BurkTr00 (status code: 429)\n",
      "Fetching: WatsCh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WatsCh00.htm\n",
      "❌ Could not fetch page for WatsCh00 (status code: 429)\n",
      "Fetching: RobiWa01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/R/RobiWa01.htm\n",
      "❌ Could not fetch page for RobiWa01 (status code: 429)\n",
      "Fetching: MetcJo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MetcJo00.htm\n",
      "❌ Could not fetch page for MetcJo00 (status code: 429)\n",
      "Fetching: ThorTy00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/ThorTy00.htm\n",
      "❌ Could not fetch page for ThorTy00 (status code: 429)\n",
      "Fetching: PickGe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PickGe00.htm\n",
      "❌ Could not fetch page for PickGe00 (status code: 429)\n",
      "Fetching: PierAl00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PierAl00.htm\n",
      "❌ Could not fetch page for PierAl00 (status code: 429)\n",
      "Fetching: MoorSk01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MoorSk01.htm\n",
      "❌ Could not fetch page for MoorSk01 (status code: 429)\n",
      "Fetching: JoneVe00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/J/JoneVe00.htm\n",
      "❌ Could not fetch page for JoneVe00 (status code: 429)\n",
      "Fetching: TolbJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TolbJa00.htm\n",
      "❌ Could not fetch page for TolbJa00 (status code: 429)\n",
      "Fetching: BellDa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/B/BellDa02.htm\n",
      "❌ Could not fetch page for BellDa02 (status code: 429)\n",
      "Fetching: GrayDa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/G/GrayDa02.htm\n",
      "❌ Could not fetch page for GrayDa02 (status code: 429)\n",
      "Fetching: EzukEr00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/E/EzukEr00.htm\n",
      "❌ Could not fetch page for EzukEr00 (status code: 429)\n",
      "Fetching: DoubRo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/D/DoubRo00.htm\n",
      "❌ Could not fetch page for DoubRo00 (status code: 429)\n",
      "Fetching: AustCa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/A/AustCa00.htm\n",
      "❌ Could not fetch page for AustCa00 (status code: 429)\n",
      "Fetching: ShakKh00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/S/ShakKh00.htm\n",
      "❌ Could not fetch page for ShakKh00 (status code: 429)\n",
      "Fetching: WashMo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WashMo00.htm\n",
      "❌ Could not fetch page for WashMo00 (status code: 429)\n",
      "Fetching: PhilKy01\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/P/PhilKy01.htm\n",
      "❌ Could not fetch page for PhilKy01 (status code: 429)\n",
      "Fetching: NailJa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/N/NailJa00.htm\n",
      "❌ Could not fetch page for NailJa00 (status code: 429)\n",
      "Fetching: WoodMi00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/W/WoodMi00.htm\n",
      "❌ Could not fetch page for WoodMi00 (status code: 429)\n",
      "Fetching: MeltBo00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/M/MeltBo00.htm\n",
      "❌ Could not fetch page for MeltBo00 (status code: 429)\n",
      "Fetching: YounDa02\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/Y/YounDa02.htm\n",
      "❌ Could not fetch page for YounDa02 (status code: 429)\n",
      "Fetching: TourSa00\n",
      "🔗 Trying URL: https://www.pro-football-reference.com/players/T/TourSa00.htm\n",
      "❌ Could not fetch page for TourSa00 (status code: 429)\n",
      "✅ Enriched dataset saved as 'wr_draft_data_enriched.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id} (status code: {response.status_code})\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # Try receiving_and_rushing\n",
    "    recv_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if recv_table:\n",
    "        tfoot = recv_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            av_td = row.find('td', {'data-stat': 'av'}) if row else None\n",
    "            if av_td:\n",
    "                career_av = av_td.text.strip()\n",
    "        else:\n",
    "            print(f\"⚠️ No tfoot in receiving_and_rushing for {player_id}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No receiving_and_rushing table for {player_id}\")\n",
    "\n",
    "    # Try snap_counts\n",
    "    snap_table = soup.find('table', {'id': 'snap_counts'})\n",
    "    if snap_table:\n",
    "        tfoot = snap_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            gp_td = row.find('td', {'data-stat': 'g'}) if row else None\n",
    "            if gp_td:\n",
    "                games_played = gp_td.text.strip()\n",
    "        else:\n",
    "            print(f\"⚠️ No tfoot in snap_counts for {player_id}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No snap_counts table for {player_id}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# Load draft data\n",
    "wr_df = pd.read_csv(\"wr_draft_data_2013_2022.csv\")\n",
    "\n",
    "# Enrich each player\n",
    "stats = []\n",
    "for pid in wr_df['Player_ID']:\n",
    "    print(f\"Fetching: {pid}\")\n",
    "    stats.append(get_player_stats(pid))\n",
    "\n",
    "# Combine dataframes\n",
    "stats_df = pd.DataFrame(stats)\n",
    "enriched_df = pd.merge(wr_df, stats_df, on='Player_ID', how='left')\n",
    "\n",
    "# Save the result\n",
    "enriched_df.to_csv(\"wr_draft_data_enriched.csv\", index=False)\n",
    "print(\"✅ Enriched dataset saved as 'wr_draft_data_enriched.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8afd2cc-58a3-49dc-a115-28b2cb97efb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': ''}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 429:\n",
    "        print(f\"🧱 Rate limit hit for {player_id} (status code: 429). Take a breather.\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id} (status code: {response.status_code})\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # receiving_and_rushing\n",
    "    recv_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if recv_table:\n",
    "        tfoot = recv_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            av_td = row.find('td', {'data-stat': 'av'}) if row else None\n",
    "            if av_td:\n",
    "                career_av = av_td.text.strip()\n",
    "\n",
    "    # snap_counts\n",
    "    snap_table = soup.find('table', {'id': 'snap_counts'})\n",
    "    if snap_table:\n",
    "        tfoot = snap_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            gp_td = row.find('td', {'data-stat': 'g'}) if row else None\n",
    "            if gp_td:\n",
    "                games_played = gp_td.text.strip()\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# 🧪 Just test D-Hop\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9665172a-2723-413c-9c62-07207ddb9440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking snap_counts for: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "📎 Full row contents from tfoot:\n",
      "<tr>\n",
      " <th class=\"left\" colspan=\"2\" data-stat=\"year_id\" scope=\"row\">\n",
      "  Career\n",
      " </th>\n",
      " <td class=\"left iz\" data-stat=\"team\">\n",
      " </td>\n",
      " <td class=\"left iz\" data-stat=\"pos\">\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"uniform_number\">\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"g\">\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"gs\">\n",
      " </td>\n",
      " <td class=\"right\" data-stat=\"offense\">\n",
      "  11874\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"off_pct\">\n",
      " </td>\n",
      " <td class=\"right\" data-stat=\"defense\">\n",
      "  4\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"def_pct\">\n",
      " </td>\n",
      " <td class=\"right\" data-stat=\"special_teams\">\n",
      "  10\n",
      " </td>\n",
      " <td class=\"right iz\" data-stat=\"st_pct\">\n",
      " </td>\n",
      "</tr>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def inspect_snap_counts(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔍 Checking snap_counts for: {url}\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'id': 'snap_counts'})\n",
    "\n",
    "    if not table:\n",
    "        print(f\"❌ No snap_counts table found for {player_id}\")\n",
    "        return\n",
    "\n",
    "    tfoot = table.find('tfoot')\n",
    "    if not tfoot:\n",
    "        print(f\"❌ No <tfoot> found in snap_counts for {player_id}\")\n",
    "        return\n",
    "\n",
    "    row = tfoot.find('tr')\n",
    "    print(\"📎 Full row contents from tfoot:\")\n",
    "    print(row.prettify())\n",
    "\n",
    "inspect_snap_counts(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a7ccda0-de94-44b4-b34c-99883ce882bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id} (status code: {response.status_code})\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # --- Get Career AV from receiving_and_rushing ---\n",
    "    career_av = 'N/A'\n",
    "    recv_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if recv_table:\n",
    "        tfoot = recv_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            av_td = row.find('td', {'data-stat': 'av'}) if row else None\n",
    "            if av_td:\n",
    "                career_av = av_td.text.strip()\n",
    "\n",
    "    # --- Get Games Played from commented stats table ---\n",
    "    games_played = 'N/A'\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        if 'id=\"stats\"' in comment:\n",
    "            comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "            tfoot = comment_soup.find('tfoot')\n",
    "            if tfoot:\n",
    "                row = tfoot.find('tr')\n",
    "                games_td = row.find('td', {'data-stat': 'g'}) if row else None\n",
    "                if games_td:\n",
    "                    games_played = games_td.text.strip()\n",
    "            break  # Only need the first valid stats block\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# 🔍 Test on D-Hop\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f2b82b5-425f-4881-8894-aec11b34d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_player_stats_simple(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Get Career AV from receiving_and_rushing (as before)\n",
    "    career_av = 'N/A'\n",
    "    recv_table = soup.find('table', {'id': 'receiving_and_rushing'})\n",
    "    if recv_table:\n",
    "        tfoot = recv_table.find('tfoot')\n",
    "        if tfoot:\n",
    "            row = tfoot.find('tr')\n",
    "            av_td = row.find('td', {'data-stat': 'av'}) if row else None\n",
    "            if av_td:\n",
    "                career_av = av_td.text.strip()\n",
    "\n",
    "    # Get Games Played from the top header section\n",
    "    games_played = 'N/A'\n",
    "    meta_div = soup.find('div', id='meta')\n",
    "    if meta_div:\n",
    "        strongs = meta_div.find_all('strong')\n",
    "        for s in strongs:\n",
    "            if 'G' in s.text and 'GS' not in s.text:  # Avoid Games Started\n",
    "                parent = s.parent\n",
    "                if parent and parent.next_sibling:\n",
    "                    games_played = parent.next_sibling.strip()\n",
    "                    break\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# Test it\n",
    "get_player_stats_simple(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0993160-e5a7-487e-958d-d5ab4d0bec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # Look inside div#meta\n",
    "    meta_div = soup.find('div', id='meta')\n",
    "    if meta_div:\n",
    "        for p in meta_div.find_all('p'):\n",
    "            if p.strong:\n",
    "                label = p.strong.text.strip()\n",
    "                value = p.get_text(strip=True).replace(label, '').strip(': ').strip()\n",
    "                if label == 'G':\n",
    "                    games_played = value\n",
    "                elif label == 'AV':\n",
    "                    career_av = value\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played\n",
    "    }\n",
    "\n",
    "# Try it on our OG\n",
    "get_player_stats(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "086f9f17-7f3a-470f-9103-24e120a2540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Data not found in meta'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A',\n",
    "            'Note': 'Failed to fetch page'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    meta_div = soup.find('div', id='meta')\n",
    "    \n",
    "    if not meta_div:\n",
    "        print(f\"❌ No meta div found for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A',\n",
    "            'Note': 'No meta div'\n",
    "        }\n",
    "\n",
    "    # Get text content from meta and clean it\n",
    "    meta_text = meta_div.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    # Use regex to pull AV and Games Played (G)\n",
    "    av_match = re.search(r'AV:\\s*(\\d+)', meta_text)\n",
    "    g_match = re.search(r'G:\\s*(\\d+)', meta_text)\n",
    "\n",
    "    career_av = av_match.group(1) if av_match else 'N/A'\n",
    "    games_played = g_match.group(1) if g_match else 'N/A'\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Success' if av_match or g_match else 'Data not found in meta'\n",
    "    }\n",
    "\n",
    "# Test it\n",
    "print(get_player_stats(\"HopkDe00\"))  # DeAndre Hopkins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ebb217a-af55-4e8d-81ca-8854e491f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'No data found in tables'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if not response.ok:\n",
    "        print(f\"❌ Could not fetch page for {player_id}\")\n",
    "        return {\n",
    "            'Player_ID': player_id,\n",
    "            'Career_AV': 'N/A',\n",
    "            'Games_Played': 'N/A',\n",
    "            'Note': 'Failed to fetch page'\n",
    "        }\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "\n",
    "        # Parse AV table\n",
    "        av_table = comment_soup.find('table', id='av')\n",
    "        if av_table:\n",
    "            df_av = pd.read_html(str(av_table))[0]\n",
    "            if 'AV' in df_av.columns and 'Year' in df_av.columns:\n",
    "                df_av = df_av[df_av['Year'] != 'Career']  # Drop summary if exists\n",
    "                total_av = df_av['AV'].sum()\n",
    "                career_av = str(int(total_av))\n",
    "\n",
    "        # Parse Games Played from Games table\n",
    "        games_table = comment_soup.find('table', id='games')\n",
    "        if games_table:\n",
    "            df_games = pd.read_html(str(games_table))[0]\n",
    "            if 'G' in df_games.columns:\n",
    "                df_games = df_games[df_games['Year'] != 'Career']  # Drop summary if exists\n",
    "                total_games = df_games['G'].sum()\n",
    "                games_played = str(int(total_games))\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Success' if career_av != 'N/A' or games_played != 'N/A' else 'No data found in tables'\n",
    "    }\n",
    "\n",
    "# Test it again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16450f90-36d6-44e4-8fcf-eed5cc24c9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Checking URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "📋 Tables found in comments:\n",
      " - fantasy\n",
      " - sim_scores\n",
      " - all_pro\n",
      " - combine\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "\n",
    "def inspect_player_tables(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Checking URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if not response.ok:\n",
    "        print(\"❌ Failed to fetch page.\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "    found_tables = []\n",
    "\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "        for table in comment_soup.find_all('table'):\n",
    "            table_id = table.get('id')\n",
    "            if table_id:\n",
    "                found_tables.append(table_id)\n",
    "\n",
    "    print(\"📋 Tables found in comments:\")\n",
    "    for table_id in found_tables:\n",
    "        print(f\" - {table_id}\")\n",
    "\n",
    "# Run this to debug what tables are actually present\n",
    "inspect_player_tables(\"HopkDe00\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "abac24e3-63e9-49f1-b537-f5aeb31d410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "⚠️ Error parsing visible receiving_and_rushing: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Parsed from visible tables and comments'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/s8f61mz57yz4xkpds4b4ydqm0000gn/T/ipykernel_18620/1076987254.py:23: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(visible_games_table))[0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # --- Step 1: Try visible tables first ---\n",
    "    visible_games_table = soup.find('table', id='receiving_and_rushing')\n",
    "    if visible_games_table:\n",
    "        try:\n",
    "            df = pd.read_html(str(visible_games_table))[0]\n",
    "            df = df[df['Year'] != 'Career']\n",
    "            if 'G' in df.columns:\n",
    "                total_games = df['G'].sum()\n",
    "                games_played = str(int(total_games))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing visible receiving_and_rushing: {e}\")\n",
    "\n",
    "    # --- Step 2: Try to find AV in comments ---\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "        value_table = comment_soup.find('table', id='value')  # Career AV table\n",
    "\n",
    "        if value_table:\n",
    "            try:\n",
    "                df_value = pd.read_html(str(value_table))[0]\n",
    "                if 'AV' in df_value.columns and 'Year' in df_value.columns:\n",
    "                    df_value = df_value[df_value['Year'] != 'Career']\n",
    "                    total_av = df_value['AV'].sum()\n",
    "                    career_av = str(int(total_av))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error parsing value table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from visible tables and comments'\n",
    "    }\n",
    "\n",
    "# Test again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9723ad6-05dd-4365-9cef-a015b7ed0818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "⚠️ Error parsing visible receiving_and_rushing: Missing optional dependency 'lxml'.  Use pip or conda to install lxml.\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Parsed from visible tables and comments'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7n/s8f61mz57yz4xkpds4b4ydqm0000gn/T/ipykernel_18620/1076987254.py:23: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(visible_games_table))[0]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # --- Step 1: Try visible tables first ---\n",
    "    visible_games_table = soup.find('table', id='receiving_and_rushing')\n",
    "    if visible_games_table:\n",
    "        try:\n",
    "            df = pd.read_html(str(visible_games_table))[0]\n",
    "            df = df[df['Year'] != 'Career']\n",
    "            if 'G' in df.columns:\n",
    "                total_games = df['G'].sum()\n",
    "                games_played = str(int(total_games))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing visible receiving_and_rushing: {e}\")\n",
    "\n",
    "    # --- Step 2: Try to find AV in comments ---\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "        value_table = comment_soup.find('table', id='value')  # Career AV table\n",
    "\n",
    "        if value_table:\n",
    "            try:\n",
    "                df_value = pd.read_html(str(value_table))[0]\n",
    "                if 'AV' in df_value.columns and 'Year' in df_value.columns:\n",
    "                    df_value = df_value[df_value['Year'] != 'Career']\n",
    "                    total_av = df_value['AV'].sum()\n",
    "                    career_av = str(int(total_av))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error parsing value table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from visible tables and comments'\n",
    "    }\n",
    "\n",
    "# Test again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb549930-4557-4fc9-916f-fe7cb83693d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-5.4.0-cp313-cp313-macosx_10_13_x86_64.whl.metadata (3.5 kB)\n",
      "Downloading lxml-5.4.0-cp313-cp313-macosx_10_13_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d04723d-11f6-4feb-b9af-fb557867096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "from io import StringIO  # 👈 for fixing future warning\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # --- Step 1: Try visible tables first ---\n",
    "    visible_games_table = soup.find('table', id='receiving_and_rushing')\n",
    "    if visible_games_table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(visible_games_table)))[0]\n",
    "            df = df[df['Year'] != 'Career']\n",
    "            if 'G' in df.columns:\n",
    "                total_games = df['G'].sum()\n",
    "                games_played = str(int(total_games))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing visible receiving_and_rushing: {e}\")\n",
    "\n",
    "    # --- Step 2: Try to find AV in comments ---\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "        value_table = comment_soup.find('table', id='value')  # Career AV table\n",
    "\n",
    "        if value_table:\n",
    "            try:\n",
    "                df_value = pd.read_html(StringIO(str(value_table)))[0]\n",
    "                if 'AV' in df_value.columns and 'Year' in df_value.columns:\n",
    "                    df_value = df_value[df_value['Year'] != 'Career']\n",
    "                    total_av = df_value['AV'].sum()\n",
    "                    career_av = str(int(total_av))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error parsing value table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from visible tables and comments'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10036868-0ce1-4086-b94d-352b4ab448c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "from io import StringIO  # 👈 for fixing future warning\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        print(f\"❌ Failed to fetch page for {player_id}\")\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    # --- Step 1: Try visible tables first ---\n",
    "    visible_games_table = soup.find('table', id='receiving_and_rushing')\n",
    "    if visible_games_table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(visible_games_table)))[0]\n",
    "            df = df[df['Year'] != 'Career']\n",
    "            if 'G' in df.columns:\n",
    "                total_games = df['G'].sum()\n",
    "                games_played = str(int(total_games))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing visible receiving_and_rushing: {e}\")\n",
    "\n",
    "    # --- Step 2: Try to find AV in comments ---\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment_soup = BeautifulSoup(comment, 'html.parser')\n",
    "        value_table = comment_soup.find('table', id='value')  # Career AV table\n",
    "\n",
    "        if value_table:\n",
    "            try:\n",
    "                df_value = pd.read_html(StringIO(str(value_table)))[0]\n",
    "                if 'AV' in df_value.columns and 'Year' in df_value.columns:\n",
    "                    df_value = df_value[df_value['Year'] != 'Career']\n",
    "                    total_av = df_value['AV'].sum()\n",
    "                    career_av = str(int(total_av))\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error parsing value table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from visible tables and comments'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9b6120d-91d2-42bb-b635-8d094e70f479",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Year' 'G'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m table:\n\u001b[32m     14\u001b[39m     df = pd.read_html(StringIO(\u001b[38;5;28mstr\u001b[39m(table)))[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mYear\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mG\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Just to see the games played\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m❌ Table not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/indexes/multi.py:2763\u001b[39m, in \u001b[36mMultiIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   2760\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keyarr) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keyarr[\u001b[32m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m   2761\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m._get_indexer_level_0(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m2763\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2764\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._get_indexer_strict(key, axis_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Code/wr-data-scraper2/.venv/lib/python3.13/site-packages/pandas/core/indexes/multi.py:2781\u001b[39m, in \u001b[36mMultiIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   2779\u001b[39m cmask = check == -\u001b[32m1\u001b[39m\n\u001b[32m   2780\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cmask.any():\n\u001b[32m-> \u001b[39m\u001b[32m2781\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr[cmask]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2782\u001b[39m \u001b[38;5;66;03m# We get here when levels still contain values which are not\u001b[39;00m\n\u001b[32m   2783\u001b[39m \u001b[38;5;66;03m# actually in Index anymore\u001b[39;00m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['Year' 'G'] not in index\""
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://www.pro-football-reference.com/players/H/HopkDe00.htm\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Try to extract one table directly\n",
    "table = soup.find('table', id='receiving_and_rushing')\n",
    "if table:\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    print(df[['Year', 'G']])  # Just to see the games played\n",
    "else:\n",
    "    print(\"❌ Table not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63d08c94-3ec8-452c-84e6-472d1b23f926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Columns:\n",
      "[('Unnamed: 0_level_0', 'Season'), ('Unnamed: 1_level_0', 'Age'), ('Unnamed: 2_level_0', 'Team'), ('Unnamed: 3_level_0', 'Lg'), ('Unnamed: 4_level_0', 'Pos'), ('Unnamed: 5_level_0', 'G'), ('Unnamed: 6_level_0', 'GS'), ('Receiving', 'Tgt'), ('Receiving', 'Rec'), ('Receiving', 'Yds'), ('Receiving', 'Y/R'), ('Receiving', 'TD'), ('Receiving', '1D'), ('Receiving', 'Succ%'), ('Receiving', 'Lng'), ('Receiving', 'R/G'), ('Receiving', 'Y/G'), ('Receiving', 'Ctch%'), ('Receiving', 'Y/Tgt'), ('Rushing', 'Att'), ('Rushing', 'Yds'), ('Rushing', 'TD'), ('Rushing', '1D'), ('Rushing', 'Succ%'), ('Rushing', 'Lng'), ('Rushing', 'Y/A'), ('Rushing', 'Y/G'), ('Rushing', 'A/G'), ('Scrimmage', 'Touch'), ('Scrimmage', 'Y/Tch'), ('Scrimmage', 'YScm'), ('Scrimmage', 'RRTD'), ('Unnamed: 32_level_0', 'Fmb'), ('Unnamed: 33_level_0', 'AV'), ('Unnamed: 34_level_0', 'Awards')]\n",
      "\n",
      "🧾 First few rows:\n",
      "  Unnamed: 0_level_0 Unnamed: 1_level_0 Unnamed: 2_level_0 Unnamed: 3_level_0  \\\n",
      "              Season                Age               Team                 Lg   \n",
      "0               2013                 21                HOU                NFL   \n",
      "1               2014                 22                HOU                NFL   \n",
      "2               2015                 23                HOU                NFL   \n",
      "3               2016                 24                HOU                NFL   \n",
      "4               2017                 25                HOU                NFL   \n",
      "\n",
      "  Unnamed: 4_level_0 Unnamed: 5_level_0 Unnamed: 6_level_0 Receiving         \\\n",
      "                 Pos                  G                 GS       Tgt    Rec   \n",
      "0                 WR               16.0               16.0      91.0   52.0   \n",
      "1                 WR               16.0               16.0     127.0   76.0   \n",
      "2                 WR               16.0               16.0     192.0  111.0   \n",
      "3                 WR               16.0               16.0     151.0   78.0   \n",
      "4                 WR               15.0               15.0     174.0   96.0   \n",
      "\n",
      "           ... Rushing           Scrimmage                      \\\n",
      "      Yds  ...     Y/A  Y/G  A/G     Touch Y/Tch    YScm  RRTD   \n",
      "0   802.0  ...     NaN  0.0  0.0      52.0  15.4   802.0   2.0   \n",
      "1  1210.0  ...     NaN  0.0  0.0      76.0  15.9  1210.0   6.0   \n",
      "2  1521.0  ...     NaN  0.0  0.0     111.0  13.7  1521.0  11.0   \n",
      "3   954.0  ...     NaN  0.0  0.0      78.0  12.2   954.0   4.0   \n",
      "4  1378.0  ...     NaN  0.0  0.0      96.0  14.4  1378.0  13.0   \n",
      "\n",
      "  Unnamed: 32_level_0 Unnamed: 33_level_0 Unnamed: 34_level_0  \n",
      "                  Fmb                  AV              Awards  \n",
      "0                 1.0                 5.0                 NaN  \n",
      "1                 2.0                10.0                 NaN  \n",
      "2                 1.0                11.0             PB,AP-2  \n",
      "3                 0.0                 7.0                 NaN  \n",
      "4                 1.0                10.0   PB,AP-1,AP OPoY-4  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://www.pro-football-reference.com/players/H/HopkDe00.htm\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Grab the visible receiving + rushing table\n",
    "table = soup.find('table', id='receiving_and_rushing')\n",
    "if table:\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    \n",
    "    print(\"📋 Columns:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    print(\"\\n🧾 First few rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"❌ Table not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4959184b-13c4-4176-aaca-e06ff8b59ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': '333', 'Games_Played': '567', 'Note': 'Parsed from visible receiving_and_rushing table'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup, Comment\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    table = soup.find('table', id='receiving_and_rushing')\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            # Flatten columns\n",
    "            df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "            df = df[df['Season'] != 'Career']  # Drop total row if present\n",
    "\n",
    "            if 'G' in df.columns:\n",
    "                games_played = str(int(df['G'].sum()))\n",
    "\n",
    "            if 'AV' in df.columns:\n",
    "                career_av = str(int(df['AV'].sum()))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from visible receiving_and_rushing table'\n",
    "    }\n",
    "\n",
    "# Try it\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53ca3ed3-fbea-4cfc-8cda-b425e0c28166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Parsed from Career row'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    table = soup.find('table', id='receiving_and_rushing')\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "            career_row = df[df['Season'] == 'Career']\n",
    "            if not career_row.empty:\n",
    "                if 'G' in career_row.columns:\n",
    "                    games_played = str(int(career_row.iloc[0]['G']))\n",
    "                if 'AV' in career_row.columns:\n",
    "                    career_av = str(int(career_row.iloc[0]['AV']))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from Career row'\n",
    "    }\n",
    "\n",
    "# Try it again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4c64fbf-e36d-44a0-84e8-d4e532bbb6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Parsed from final row (Career)'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    table = soup.find('table', id='receiving_and_rushing')\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "            # Get last row if Season is NaN (which is often the Career row)\n",
    "            last_row = df.iloc[-1]\n",
    "            if pd.isna(last_row['Season']) or str(last_row['Season']).strip().lower() == 'career':\n",
    "                if 'G' in last_row:\n",
    "                    games_played = str(int(last_row['G']))\n",
    "                if 'AV' in last_row:\n",
    "                    career_av = str(int(last_row['AV']))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from final row (Career)'\n",
    "    }\n",
    "\n",
    "# Try it again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b8c73de-2541-4c25-b5c9-553002f3dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Last few rows:\n",
      "         Season          Age         Team           Lg  Pos     G    GS  \\\n",
      "18  ARI (3 Yrs)  ARI (3 Yrs)  ARI (3 Yrs)  ARI (3 Yrs)  NaN  35.0  35.0   \n",
      "19  TEN (2 Yrs)  TEN (2 Yrs)  TEN (2 Yrs)  TEN (2 Yrs)  NaN  23.0  19.0   \n",
      "20   KAN (1 Yr)   KAN (1 Yr)   KAN (1 Yr)   KAN (1 Yr)  NaN  10.0   5.0   \n",
      "\n",
      "      Tgt    Rec     Yds  ...  Y/A  Y/G  A/G  Touch  Y/Tch    YScm  RRTD  Fmb  \\\n",
      "18  320.0  221.0  2696.0  ...  1.0  0.0  0.0  222.0   12.1  2697.0  17.0  5.0   \n",
      "19  158.0   90.0  1230.0  ...  4.5  0.4  0.1   92.0   13.5  1239.0   8.0  1.0   \n",
      "20   59.0   41.0   437.0  ...  NaN  0.0  0.0   41.0   10.7   437.0   4.0  0.0   \n",
      "\n",
      "      AV  Awards  \n",
      "18  24.0     NaN  \n",
      "19  11.0     NaN  \n",
      "20   4.0     NaN  \n",
      "\n",
      "[3 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://www.pro-football-reference.com/players/H/HopkDe00.htm\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "table = soup.find('table', id='receiving_and_rushing')\n",
    "if table:\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "    df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "    print(\"📄 Last few rows:\")\n",
    "    print(df.tail(3))\n",
    "else:\n",
    "    print(\"❌ Table not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96fe2ee6-e8d3-4c40-80d8-bd706f5d3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': '111', 'Games_Played': '194', 'Note': 'Parsed from year rows only'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    table = soup.find('table', id='receiving_and_rushing')\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "            # Keep only rows where 'Season' looks like a 4-digit year\n",
    "            df = df[df['Season'].astype(str).str.fullmatch(r'\\d{4}')]\n",
    "\n",
    "            if 'G' in df.columns:\n",
    "                games_played = str(int(df['G'].sum()))\n",
    "\n",
    "            if 'AV' in df.columns:\n",
    "                career_av = str(int(df['AV'].sum()))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from year rows only'\n",
    "    }\n",
    "\n",
    "# Test it again\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d7eb14f-d380-4db6-acef-4e831c49a820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 Trying URL: https://www.pro-football-reference.com/players/H/HopkDe00.htm\n",
      "{'Player_ID': 'HopkDe00', 'Career_AV': '106', 'Games_Played': '178', 'Note': 'Parsed from distinct season rows only'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def get_player_stats(player_id):\n",
    "    url = f\"https://www.pro-football-reference.com/players/{player_id[0]}/{player_id}.htm\"\n",
    "    print(f\"🔗 Trying URL: {url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if not response.ok:\n",
    "        return {'Player_ID': player_id, 'Career_AV': 'N/A', 'Games_Played': 'N/A', 'Note': 'Request failed'}\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    career_av = 'N/A'\n",
    "    games_played = 'N/A'\n",
    "\n",
    "    table = soup.find('table', id='receiving_and_rushing')\n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(StringIO(str(table)))[0]\n",
    "            df.columns = [col[1] if isinstance(col, tuple) else col for col in df.columns]\n",
    "\n",
    "            # Filter for valid 4-digit seasons only\n",
    "            df = df[df['Season'].astype(str).str.fullmatch(r'\\d{4}')]\n",
    "\n",
    "            # Keep only the first row per season to avoid duplicates\n",
    "            df = df.drop_duplicates(subset='Season', keep='first')\n",
    "\n",
    "            if 'G' in df.columns:\n",
    "                games_played = str(int(df['G'].sum()))\n",
    "\n",
    "            if 'AV' in df.columns:\n",
    "                career_av = str(int(df['AV'].sum()))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error parsing table: {e}\")\n",
    "\n",
    "    return {\n",
    "        'Player_ID': player_id,\n",
    "        'Career_AV': career_av,\n",
    "        'Games_Played': games_played,\n",
    "        'Note': 'Parsed from distinct season rows only'\n",
    "    }\n",
    "\n",
    "# Final test\n",
    "print(get_player_stats(\"HopkDe00\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fee267-e16f-472f-abf8-23f248bdce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
